{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/jupyter/inspace/sang-min/myo_proejct\n",
      "30\n",
      "./dataset_2018_05_16/1/\n",
      "15\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 16, 16, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 128)       1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 128)       64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32, 32, 256)       128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 64, 64, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 64, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 64, 64, 512)       256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 64, 64, 512)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 128, 128, 512)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 128, 128, 256)     1179904   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 128, 128, 256)     512       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 128, 128, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 128, 128, 1)       2305      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 128, 128, 1)       0         \n",
      "=================================================================\n",
      "Total params: 2,686,657\n",
      "Trainable params: 2,685,665\n",
      "Non-trainable params: 992\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 128, 128, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 64, 64, 256)       1280      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 64, 64, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 64, 64, 256)       256       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 32, 32, 512)       131584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 32, 32, 512)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 32, 32, 512)       128       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 16, 16, 256)       524544    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 16, 16, 256)       64        \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 8, 8, 128)         131200    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 8, 8, 128)         32        \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 4, 4, 128)         65664     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 4, 4, 128)         16        \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 4, 4, 1)           513       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 855,298\n",
      "Trainable params: 855,050\n",
      "Non-trainable params: 248\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 128, 128, 1)       2686657   \n",
      "_________________________________________________________________\n",
      "model_2 (Model)              (None, 1)                 855298    \n",
      "=================================================================\n",
      "Total params: 3,541,955\n",
      "Trainable params: 2,685,665\n",
      "Non-trainable params: 856,290\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/engine/training.py:973: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss real: 1.273300] [D loss fake: 6.803737] [D loss: 8.077037] [G loss: 0.233347]\n",
      "gan imaga2 :  (128, 128, 1)\n",
      "1 [D loss real: 0.429120] [D loss fake: 0.863993] [D loss: 1.293113] [G loss: 3.395236]\n",
      "2 [D loss real: 0.339489] [D loss fake: 0.614672] [D loss: 0.954161] [G loss: 3.036199]\n",
      "3 [D loss real: 0.218471] [D loss fake: 0.398538] [D loss: 0.617009] [G loss: 1.774432]\n",
      "4 [D loss real: 0.284366] [D loss fake: 0.434164] [D loss: 0.718530] [G loss: 1.682467]\n",
      "5 [D loss real: 0.267459] [D loss fake: 0.405632] [D loss: 0.673092] [G loss: 1.927379]\n",
      "6 [D loss real: 0.237164] [D loss fake: 0.445963] [D loss: 0.683127] [G loss: 1.821254]\n",
      "7 [D loss real: 0.078805] [D loss fake: 0.433467] [D loss: 0.512272] [G loss: 1.764116]\n",
      "8 [D loss real: 0.254449] [D loss fake: 0.401633] [D loss: 0.656082] [G loss: 1.942204]\n",
      "9 [D loss real: 0.164572] [D loss fake: 0.396695] [D loss: 0.561267] [G loss: 1.825456]\n",
      "10 [D loss real: 0.312446] [D loss fake: 0.432673] [D loss: 0.745119] [G loss: 1.858110]\n",
      "11 [D loss real: 0.190920] [D loss fake: 0.445030] [D loss: 0.635950] [G loss: 1.886693]\n",
      "12 [D loss real: 0.127028] [D loss fake: 0.431988] [D loss: 0.559017] [G loss: 1.779211]\n",
      "./dataset_2018_05_16/2/\n",
      "13 [D loss real: 0.192324] [D loss fake: 0.454712] [D loss: 0.647036] [G loss: 1.767287]\n",
      "14 [D loss real: 0.275786] [D loss fake: 0.409041] [D loss: 0.684827] [G loss: 1.907309]\n",
      "15 [D loss real: 0.298885] [D loss fake: 0.397311] [D loss: 0.696195] [G loss: 1.987907]\n",
      "16 [D loss real: 0.218191] [D loss fake: 0.416377] [D loss: 0.634569] [G loss: 1.845296]\n",
      "17 [D loss real: 0.352229] [D loss fake: 0.442389] [D loss: 0.794618] [G loss: 1.745275]\n",
      "18 [D loss real: 0.241596] [D loss fake: 0.450136] [D loss: 0.691732] [G loss: 1.878338]\n",
      "19 [D loss real: 0.223390] [D loss fake: 0.412870] [D loss: 0.636259] [G loss: 1.863868]\n",
      "20 [D loss real: 0.177809] [D loss fake: 0.448442] [D loss: 0.626251] [G loss: 1.699978]\n",
      "21 [D loss real: 0.145361] [D loss fake: 0.434917] [D loss: 0.580277] [G loss: 1.909970]\n",
      "22 [D loss real: 0.225545] [D loss fake: 0.404479] [D loss: 0.630024] [G loss: 1.876511]\n",
      "23 [D loss real: 0.300989] [D loss fake: 0.434482] [D loss: 0.735470] [G loss: 1.651603]\n",
      "24 [D loss real: 0.315614] [D loss fake: 0.439359] [D loss: 0.754973] [G loss: 1.751635]\n",
      "25 [D loss real: 0.318603] [D loss fake: 0.413250] [D loss: 0.731853] [G loss: 1.933072]\n",
      "26 [D loss real: 0.158383] [D loss fake: 0.428937] [D loss: 0.587320] [G loss: 1.991753]\n",
      "./dataset_2018_05_16/3/\n",
      "27 [D loss real: 0.246096] [D loss fake: 0.492344] [D loss: 0.738440] [G loss: 1.441199]\n",
      "28 [D loss real: 0.233136] [D loss fake: 0.715685] [D loss: 0.948821] [G loss: 3.360105]\n",
      "29 [D loss real: 0.330670] [D loss fake: 0.596331] [D loss: 0.927001] [G loss: 2.562288]\n",
      "30 [D loss real: 0.191380] [D loss fake: 0.417860] [D loss: 0.609240] [G loss: 1.519601]\n",
      "31 [D loss real: 0.163792] [D loss fake: 0.477425] [D loss: 0.641217] [G loss: 1.840140]\n",
      "32 [D loss real: 0.269439] [D loss fake: 0.422436] [D loss: 0.691875] [G loss: 2.071157]\n",
      "33 [D loss real: 0.264384] [D loss fake: 0.415964] [D loss: 0.680348] [G loss: 1.740067]\n",
      "34 [D loss real: 0.225870] [D loss fake: 0.431061] [D loss: 0.656931] [G loss: 1.925947]\n",
      "35 [D loss real: 0.262990] [D loss fake: 0.423645] [D loss: 0.686635] [G loss: 1.829314]\n",
      "36 [D loss real: 0.202058] [D loss fake: 0.426858] [D loss: 0.628916] [G loss: 1.777426]\n",
      "37 [D loss real: 0.211875] [D loss fake: 0.396834] [D loss: 0.608709] [G loss: 1.964610]\n",
      "38 [D loss real: 0.197935] [D loss fake: 0.444747] [D loss: 0.642682] [G loss: 1.665281]\n",
      "39 [D loss real: 0.202556] [D loss fake: 0.437268] [D loss: 0.639824] [G loss: 1.906170]\n",
      "40 [D loss real: 0.167056] [D loss fake: 0.437743] [D loss: 0.604798] [G loss: 1.719116]\n",
      "41 [D loss real: 0.258020] [D loss fake: 0.428664] [D loss: 0.686684] [G loss: 1.886169]\n",
      "./dataset_2018_05_16/4/\n",
      "42 [D loss real: 0.237791] [D loss fake: 0.437722] [D loss: 0.675512] [G loss: 1.761784]\n",
      "43 [D loss real: 0.270478] [D loss fake: 0.493955] [D loss: 0.764433] [G loss: 1.953570]\n",
      "44 [D loss real: 0.344670] [D loss fake: 0.444710] [D loss: 0.789379] [G loss: 2.253724]\n",
      "45 [D loss real: 0.178362] [D loss fake: 0.424554] [D loss: 0.602915] [G loss: 1.621140]\n",
      "46 [D loss real: 0.196328] [D loss fake: 0.442299] [D loss: 0.638627] [G loss: 1.958085]\n",
      "47 [D loss real: 0.194769] [D loss fake: 0.404598] [D loss: 0.599367] [G loss: 2.193733]\n",
      "48 [D loss real: 0.122865] [D loss fake: 0.458269] [D loss: 0.581135] [G loss: 1.562884]\n",
      "49 [D loss real: 0.199295] [D loss fake: 0.462503] [D loss: 0.661798] [G loss: 1.794274]\n",
      "50 [D loss real: 0.239743] [D loss fake: 0.438523] [D loss: 0.678266] [G loss: 1.847478]\n",
      "51 [D loss real: 0.254755] [D loss fake: 0.391146] [D loss: 0.645901] [G loss: 1.912226]\n",
      "52 [D loss real: 0.201508] [D loss fake: 0.444093] [D loss: 0.645601] [G loss: 1.669902]\n",
      "53 [D loss real: 0.159274] [D loss fake: 0.444930] [D loss: 0.604204] [G loss: 1.744890]\n",
      "54 [D loss real: 0.176034] [D loss fake: 0.455512] [D loss: 0.631546] [G loss: 1.749427]\n",
      "55 [D loss real: 0.235688] [D loss fake: 0.439499] [D loss: 0.675187] [G loss: 1.773744]\n",
      "./dataset_2018_05_16/5/\n",
      "56 [D loss real: 0.261123] [D loss fake: 0.410218] [D loss: 0.671341] [G loss: 1.968690]\n",
      "57 [D loss real: 0.160495] [D loss fake: 0.455534] [D loss: 0.616028] [G loss: 1.710394]\n",
      "58 [D loss real: 0.205691] [D loss fake: 0.385795] [D loss: 0.591486] [G loss: 2.115362]\n",
      "59 [D loss real: 0.204028] [D loss fake: 0.411255] [D loss: 0.615283] [G loss: 2.030254]\n",
      "60 [D loss real: 0.158624] [D loss fake: 0.434453] [D loss: 0.593077] [G loss: 1.693016]\n",
      "61 [D loss real: 0.245092] [D loss fake: 0.417173] [D loss: 0.662265] [G loss: 1.962191]\n",
      "62 [D loss real: 0.170546] [D loss fake: 0.414138] [D loss: 0.584685] [G loss: 1.823677]\n",
      "63 [D loss real: 0.284728] [D loss fake: 0.463011] [D loss: 0.747739] [G loss: 1.753868]\n",
      "64 [D loss real: 0.257527] [D loss fake: 0.427017] [D loss: 0.684544] [G loss: 1.817875]\n",
      "65 [D loss real: 0.266932] [D loss fake: 0.394253] [D loss: 0.661185] [G loss: 1.981555]\n",
      "66 [D loss real: 0.169181] [D loss fake: 0.426699] [D loss: 0.595880] [G loss: 1.724275]\n",
      "67 [D loss real: 0.152802] [D loss fake: 0.406208] [D loss: 0.559010] [G loss: 1.934346]\n",
      "68 [D loss real: 0.154877] [D loss fake: 0.430181] [D loss: 0.585058] [G loss: 1.847829]\n",
      "69 [D loss real: 0.268307] [D loss fake: 0.436557] [D loss: 0.704864] [G loss: 1.835959]\n",
      "./dataset_2018_05_16/6/\n",
      "70 [D loss real: 0.302788] [D loss fake: 0.404185] [D loss: 0.706974] [G loss: 1.987669]\n",
      "71 [D loss real: 0.252634] [D loss fake: 0.404304] [D loss: 0.656938] [G loss: 1.850569]\n",
      "72 [D loss real: 0.238023] [D loss fake: 0.416512] [D loss: 0.654536] [G loss: 1.773046]\n",
      "73 [D loss real: 0.235324] [D loss fake: 0.400938] [D loss: 0.636262] [G loss: 1.901550]\n",
      "74 [D loss real: 0.186840] [D loss fake: 0.388058] [D loss: 0.574898] [G loss: 1.918083]\n",
      "75 [D loss real: 0.140675] [D loss fake: 0.451199] [D loss: 0.591873] [G loss: 0.216379]\n",
      "76 [D loss real: 0.116957] [D loss fake: 1.670273] [D loss: 1.787230] [G loss: 8.337796]\n",
      "77 [D loss real: 0.073840] [D loss fake: 2.994944] [D loss: 3.068784] [G loss: 2.587143]\n",
      "78 [D loss real: 0.246630] [D loss fake: 0.495482] [D loss: 0.742112] [G loss: 2.559664]\n",
      "79 [D loss real: 0.291575] [D loss fake: 0.410559] [D loss: 0.702135] [G loss: 1.529887]\n",
      "80 [D loss real: 0.228708] [D loss fake: 0.467975] [D loss: 0.696683] [G loss: 1.772498]\n",
      "81 [D loss real: 0.188084] [D loss fake: 0.418343] [D loss: 0.606427] [G loss: 2.037339]\n",
      "82 [D loss real: 0.197363] [D loss fake: 0.419830] [D loss: 0.617193] [G loss: 1.921379]\n",
      "83 [D loss real: 0.257020] [D loss fake: 0.458792] [D loss: 0.715812] [G loss: 1.701807]\n",
      "./dataset_2018_05_16/7/\n",
      "84 [D loss real: 0.266622] [D loss fake: 0.450903] [D loss: 0.717525] [G loss: 1.679503]\n",
      "85 [D loss real: 0.176058] [D loss fake: 0.444294] [D loss: 0.620352] [G loss: 1.662646]\n",
      "86 [D loss real: 0.240477] [D loss fake: 0.418854] [D loss: 0.659332] [G loss: 1.770443]\n",
      "87 [D loss real: 0.203375] [D loss fake: 0.440088] [D loss: 0.643463] [G loss: 1.741176]\n",
      "88 [D loss real: 0.125335] [D loss fake: 0.432181] [D loss: 0.557516] [G loss: 1.803809]\n",
      "89 [D loss real: 0.397348] [D loss fake: 0.475081] [D loss: 0.872429] [G loss: 1.979772]\n",
      "90 [D loss real: 0.171019] [D loss fake: 0.452731] [D loss: 0.623750] [G loss: 1.675472]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91 [D loss real: 0.297169] [D loss fake: 0.451246] [D loss: 0.748415] [G loss: 1.693953]\n",
      "92 [D loss real: 0.105959] [D loss fake: 0.427560] [D loss: 0.533519] [G loss: 1.730070]\n",
      "93 [D loss real: 0.236599] [D loss fake: 0.393190] [D loss: 0.629789] [G loss: 1.901893]\n",
      "94 [D loss real: 0.265778] [D loss fake: 0.429654] [D loss: 0.695432] [G loss: 1.841251]\n",
      "95 [D loss real: 0.292171] [D loss fake: 0.423985] [D loss: 0.716156] [G loss: 1.843973]\n",
      "96 [D loss real: 0.184016] [D loss fake: 0.430869] [D loss: 0.614885] [G loss: 1.633896]\n",
      "97 [D loss real: 0.205275] [D loss fake: 0.444770] [D loss: 0.650046] [G loss: 1.740165]\n",
      "./dataset_2018_05_16/8/\n",
      "98 [D loss real: 0.328446] [D loss fake: 0.481547] [D loss: 0.809993] [G loss: 1.618150]\n",
      "99 [D loss real: 0.171053] [D loss fake: 0.421493] [D loss: 0.592546] [G loss: 1.957934]\n",
      "100 [D loss real: 0.193126] [D loss fake: 0.430686] [D loss: 0.623812] [G loss: 1.707080]\n",
      "101 [D loss real: 0.212493] [D loss fake: 0.423752] [D loss: 0.636246] [G loss: 1.762890]\n",
      "102 [D loss real: 0.261192] [D loss fake: 0.447628] [D loss: 0.708821] [G loss: 1.800176]\n",
      "103 [D loss real: 0.198467] [D loss fake: 0.437712] [D loss: 0.636178] [G loss: 1.761295]\n",
      "104 [D loss real: 0.137557] [D loss fake: 0.440918] [D loss: 0.578476] [G loss: 1.764470]\n",
      "105 [D loss real: 0.219420] [D loss fake: 0.454226] [D loss: 0.673646] [G loss: 1.707050]\n",
      "106 [D loss real: 0.195882] [D loss fake: 0.431107] [D loss: 0.626988] [G loss: 1.798575]\n",
      "107 [D loss real: 0.222280] [D loss fake: 0.410858] [D loss: 0.633138] [G loss: 1.892823]\n",
      "108 [D loss real: 0.217070] [D loss fake: 0.445809] [D loss: 0.662879] [G loss: 1.821795]\n",
      "109 [D loss real: 0.221694] [D loss fake: 0.413351] [D loss: 0.635045] [G loss: 1.789008]\n",
      "110 [D loss real: 0.204659] [D loss fake: 0.471920] [D loss: 0.676578] [G loss: 1.710137]\n",
      "111 [D loss real: 0.127075] [D loss fake: 0.450765] [D loss: 0.577840] [G loss: 1.710436]\n",
      "./dataset_2018_05_16/9/\n",
      "112 [D loss real: 0.149889] [D loss fake: 0.446951] [D loss: 0.596840] [G loss: 1.699043]\n",
      "113 [D loss real: 0.317339] [D loss fake: 0.402723] [D loss: 0.720062] [G loss: 1.912912]\n",
      "114 [D loss real: 0.127395] [D loss fake: 0.417504] [D loss: 0.544899] [G loss: 1.818782]\n",
      "115 [D loss real: 0.197707] [D loss fake: 0.429866] [D loss: 0.627573] [G loss: 1.807975]\n",
      "116 [D loss real: 0.063064] [D loss fake: 0.436762] [D loss: 0.499827] [G loss: 1.745725]\n",
      "117 [D loss real: 0.099915] [D loss fake: 0.410059] [D loss: 0.509974] [G loss: 1.933350]\n",
      "118 [D loss real: 0.165191] [D loss fake: 0.492428] [D loss: 0.657619] [G loss: 1.667285]\n",
      "119 [D loss real: 0.118337] [D loss fake: 0.441446] [D loss: 0.559783] [G loss: 1.726526]\n",
      "120 [D loss real: 0.308840] [D loss fake: 0.464098] [D loss: 0.772938] [G loss: 1.791271]\n",
      "121 [D loss real: 0.236155] [D loss fake: 0.377351] [D loss: 0.613506] [G loss: 1.988070]\n",
      "122 [D loss real: 0.226499] [D loss fake: 0.431411] [D loss: 0.657910] [G loss: 1.835602]\n",
      "123 [D loss real: 0.192255] [D loss fake: 0.424821] [D loss: 0.617077] [G loss: 1.780783]\n",
      "124 [D loss real: 0.089672] [D loss fake: 0.417349] [D loss: 0.507022] [G loss: 1.740564]\n",
      "125 [D loss real: 0.231295] [D loss fake: 0.386940] [D loss: 0.618235] [G loss: 2.028094]\n",
      "./dataset_2018_05_16/10/\n",
      "126 [D loss real: 0.178098] [D loss fake: 0.394103] [D loss: 0.572200] [G loss: 1.900213]\n",
      "127 [D loss real: 0.199236] [D loss fake: 0.393622] [D loss: 0.592858] [G loss: 1.854463]\n",
      "128 [D loss real: 0.166560] [D loss fake: 0.449010] [D loss: 0.615571] [G loss: 1.709518]\n",
      "129 [D loss real: 0.181235] [D loss fake: 0.419557] [D loss: 0.600792] [G loss: 1.801327]\n",
      "130 [D loss real: 0.216174] [D loss fake: 0.438668] [D loss: 0.654843] [G loss: 1.863687]\n",
      "131 [D loss real: 0.186652] [D loss fake: 0.437194] [D loss: 0.623846] [G loss: 1.779068]\n",
      "132 [D loss real: 0.272832] [D loss fake: 0.437621] [D loss: 0.710453] [G loss: 1.746756]\n",
      "133 [D loss real: 0.183840] [D loss fake: 0.403928] [D loss: 0.587768] [G loss: 1.886679]\n",
      "134 [D loss real: 0.206325] [D loss fake: 0.433232] [D loss: 0.639557] [G loss: 1.872177]\n",
      "135 [D loss real: 0.257626] [D loss fake: 0.408517] [D loss: 0.666142] [G loss: 1.828529]\n",
      "136 [D loss real: 0.266070] [D loss fake: 0.409246] [D loss: 0.675315] [G loss: 1.870066]\n",
      "137 [D loss real: 0.170490] [D loss fake: 0.450048] [D loss: 0.620537] [G loss: 1.674457]\n",
      "138 [D loss real: 0.108347] [D loss fake: 0.456304] [D loss: 0.564651] [G loss: 1.657531]\n",
      "139 [D loss real: 0.287197] [D loss fake: 0.410536] [D loss: 0.697734] [G loss: 1.964656]\n",
      "./dataset_2018_05_16/11/\n",
      "140 [D loss real: 0.277126] [D loss fake: 0.421289] [D loss: 0.698415] [G loss: 1.718895]\n",
      "141 [D loss real: 0.574012] [D loss fake: 0.822566] [D loss: 1.396578] [G loss: 1.942559]\n",
      "142 [D loss real: 0.739367] [D loss fake: 0.483302] [D loss: 1.222669] [G loss: 1.408560]\n",
      "143 [D loss real: 0.407780] [D loss fake: 0.514431] [D loss: 0.922211] [G loss: 1.644223]\n",
      "144 [D loss real: 0.354561] [D loss fake: 0.407155] [D loss: 0.761716] [G loss: 2.221266]\n",
      "145 [D loss real: 0.235148] [D loss fake: 0.427375] [D loss: 0.662523] [G loss: 2.160282]\n",
      "146 [D loss real: 0.167593] [D loss fake: 0.429383] [D loss: 0.596976] [G loss: 1.841114]\n",
      "147 [D loss real: 0.238836] [D loss fake: 0.412647] [D loss: 0.651483] [G loss: 1.864113]\n",
      "148 [D loss real: 0.128697] [D loss fake: 0.416515] [D loss: 0.545212] [G loss: 1.806497]\n",
      "149 [D loss real: 0.170540] [D loss fake: 0.407648] [D loss: 0.578187] [G loss: 1.826615]\n",
      "150 [D loss real: 0.268890] [D loss fake: 0.393948] [D loss: 0.662838] [G loss: 1.960655]\n",
      "151 [D loss real: 0.294824] [D loss fake: 0.406308] [D loss: 0.701132] [G loss: 2.000844]\n",
      "152 [D loss real: 0.241716] [D loss fake: 0.447250] [D loss: 0.688966] [G loss: 1.765501]\n",
      "153 [D loss real: 0.136970] [D loss fake: 0.411293] [D loss: 0.548263] [G loss: 1.754491]\n",
      "./dataset_2018_05_16/12/\n",
      "154 [D loss real: 0.111642] [D loss fake: 0.416209] [D loss: 0.527851] [G loss: 1.834119]\n",
      "155 [D loss real: 0.279722] [D loss fake: 0.408989] [D loss: 0.688711] [G loss: 1.931533]\n",
      "156 [D loss real: 0.132041] [D loss fake: 0.402520] [D loss: 0.534562] [G loss: 1.819963]\n",
      "157 [D loss real: 0.257905] [D loss fake: 0.422253] [D loss: 0.680159] [G loss: 1.832311]\n",
      "158 [D loss real: 0.187541] [D loss fake: 0.403212] [D loss: 0.590753] [G loss: 1.774822]\n",
      "159 [D loss real: 0.247568] [D loss fake: 0.439324] [D loss: 0.686892] [G loss: 1.782346]\n",
      "160 [D loss real: 0.234932] [D loss fake: 0.439798] [D loss: 0.674730] [G loss: 1.683691]\n",
      "161 [D loss real: 0.236539] [D loss fake: 0.412864] [D loss: 0.649403] [G loss: 1.817383]\n",
      "162 [D loss real: 0.265973] [D loss fake: 0.462328] [D loss: 0.728301] [G loss: 1.761151]\n",
      "163 [D loss real: 0.198288] [D loss fake: 0.412441] [D loss: 0.610729] [G loss: 1.814104]\n",
      "164 [D loss real: 0.150753] [D loss fake: 0.434412] [D loss: 0.585165] [G loss: 1.745803]\n",
      "165 [D loss real: 0.210778] [D loss fake: 0.437247] [D loss: 0.648025] [G loss: 1.836742]\n",
      "166 [D loss real: 0.173313] [D loss fake: 0.426743] [D loss: 0.600056] [G loss: 1.705909]\n",
      "167 [D loss real: 0.204411] [D loss fake: 0.414509] [D loss: 0.618921] [G loss: 1.779838]\n",
      "./dataset_2018_05_16/13/\n",
      "168 [D loss real: 0.148441] [D loss fake: 0.432518] [D loss: 0.580959] [G loss: 1.714463]\n",
      "169 [D loss real: 0.286023] [D loss fake: 0.434535] [D loss: 0.720558] [G loss: 1.628098]\n",
      "170 [D loss real: 0.398020] [D loss fake: 0.412422] [D loss: 0.810442] [G loss: 1.779764]\n",
      "171 [D loss real: 0.276622] [D loss fake: 0.427074] [D loss: 0.703695] [G loss: 1.785575]\n",
      "172 [D loss real: 0.359657] [D loss fake: 0.435538] [D loss: 0.795195] [G loss: 1.635394]\n",
      "173 [D loss real: 0.265040] [D loss fake: 0.447956] [D loss: 0.712995] [G loss: 1.690466]\n",
      "174 [D loss real: 0.276969] [D loss fake: 0.417491] [D loss: 0.694461] [G loss: 1.768210]\n",
      "175 [D loss real: 0.241964] [D loss fake: 0.440432] [D loss: 0.682396] [G loss: 1.653280]\n",
      "176 [D loss real: 0.325835] [D loss fake: 0.431076] [D loss: 0.756912] [G loss: 1.743742]\n",
      "177 [D loss real: 0.257227] [D loss fake: 0.395435] [D loss: 0.652662] [G loss: 1.895565]\n",
      "178 [D loss real: 0.213584] [D loss fake: 0.444215] [D loss: 0.657800] [G loss: 1.689890]\n",
      "179 [D loss real: 0.268125] [D loss fake: 0.403384] [D loss: 0.671509] [G loss: 1.810089]\n",
      "180 [D loss real: 0.285976] [D loss fake: 0.396423] [D loss: 0.682399] [G loss: 1.966010]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181 [D loss real: 0.181783] [D loss fake: 0.451670] [D loss: 0.633453] [G loss: 1.769557]\n",
      "./dataset_2018_05_16/14/\n",
      "182 [D loss real: 0.084844] [D loss fake: 0.442607] [D loss: 0.527451] [G loss: 1.656560]\n",
      "183 [D loss real: 0.188070] [D loss fake: 0.407077] [D loss: 0.595147] [G loss: 1.845914]\n",
      "184 [D loss real: 0.159724] [D loss fake: 0.434325] [D loss: 0.594049] [G loss: 1.936400]\n",
      "185 [D loss real: 0.166543] [D loss fake: 0.439312] [D loss: 0.605855] [G loss: 1.804814]\n",
      "186 [D loss real: 0.350498] [D loss fake: 0.411307] [D loss: 0.761805] [G loss: 1.910876]\n",
      "187 [D loss real: 0.226484] [D loss fake: 0.439023] [D loss: 0.665507] [G loss: 1.753605]\n",
      "188 [D loss real: 0.208632] [D loss fake: 0.413149] [D loss: 0.621782] [G loss: 1.802387]\n",
      "189 [D loss real: 0.264076] [D loss fake: 0.409994] [D loss: 0.674070] [G loss: 1.892482]\n",
      "190 [D loss real: 0.165006] [D loss fake: 0.411895] [D loss: 0.576902] [G loss: 1.870346]\n",
      "191 [D loss real: 0.250676] [D loss fake: 0.395804] [D loss: 0.646480] [G loss: 1.919562]\n",
      "192 [D loss real: 0.256240] [D loss fake: 0.408750] [D loss: 0.664990] [G loss: 1.891255]\n",
      "193 [D loss real: 0.217793] [D loss fake: 0.407969] [D loss: 0.625762] [G loss: 1.782336]\n",
      "194 [D loss real: 0.284108] [D loss fake: 0.439900] [D loss: 0.724007] [G loss: 1.912194]\n",
      "195 [D loss real: 0.262484] [D loss fake: 0.420279] [D loss: 0.682763] [G loss: 1.827046]\n",
      "./dataset_2018_05_16/15/\n",
      "196 [D loss real: 0.234714] [D loss fake: 0.426537] [D loss: 0.661251] [G loss: 1.777975]\n",
      "197 [D loss real: 0.293723] [D loss fake: 0.418699] [D loss: 0.712422] [G loss: 1.833142]\n",
      "198 [D loss real: 0.109185] [D loss fake: 0.418962] [D loss: 0.528147] [G loss: 1.756068]\n",
      "199 [D loss real: 0.188224] [D loss fake: 0.405103] [D loss: 0.593328] [G loss: 1.807222]\n",
      "200 [D loss real: 0.287214] [D loss fake: 0.404779] [D loss: 0.691993] [G loss: 1.927917]\n",
      "201 [D loss real: 0.135355] [D loss fake: 0.422731] [D loss: 0.558086] [G loss: 1.761793]\n",
      "202 [D loss real: 0.172112] [D loss fake: 0.413813] [D loss: 0.585925] [G loss: 1.774605]\n",
      "203 [D loss real: 0.168334] [D loss fake: 0.448195] [D loss: 0.616529] [G loss: 1.689268]\n",
      "204 [D loss real: 0.185544] [D loss fake: 0.406029] [D loss: 0.591574] [G loss: 1.785887]\n",
      "205 [D loss real: 0.286470] [D loss fake: 0.467844] [D loss: 0.754315] [G loss: 1.849714]\n",
      "206 [D loss real: 0.088128] [D loss fake: 0.416560] [D loss: 0.504687] [G loss: 1.669660]\n",
      "207 [D loss real: 0.269809] [D loss fake: 0.445295] [D loss: 0.715104] [G loss: 1.802922]\n",
      "208 [D loss real: 0.227278] [D loss fake: 0.396986] [D loss: 0.624264] [G loss: 1.949974]\n",
      "209 [D loss real: 0.200511] [D loss fake: 0.438738] [D loss: 0.639249] [G loss: 1.793216]\n",
      "./dataset_2018_05_16/1/\n",
      "210 [D loss real: 0.151766] [D loss fake: 0.415279] [D loss: 0.567045] [G loss: 1.784945]\n",
      "211 [D loss real: 0.282574] [D loss fake: 0.415103] [D loss: 0.697677] [G loss: 1.780274]\n",
      "212 [D loss real: 0.274270] [D loss fake: 0.416623] [D loss: 0.690893] [G loss: 1.735355]\n",
      "213 [D loss real: 0.236959] [D loss fake: 0.441665] [D loss: 0.678624] [G loss: 1.723583]\n",
      "214 [D loss real: 0.148505] [D loss fake: 0.429670] [D loss: 0.578176] [G loss: 1.741861]\n",
      "215 [D loss real: 0.199651] [D loss fake: 0.442276] [D loss: 0.641927] [G loss: 1.714882]\n",
      "216 [D loss real: 0.190317] [D loss fake: 0.444023] [D loss: 0.634340] [G loss: 1.764063]\n",
      "217 [D loss real: 0.261509] [D loss fake: 0.435047] [D loss: 0.696556] [G loss: 1.859391]\n",
      "218 [D loss real: 0.175567] [D loss fake: 0.400950] [D loss: 0.576517] [G loss: 1.840154]\n",
      "219 [D loss real: 0.161164] [D loss fake: 0.436800] [D loss: 0.597964] [G loss: 1.761787]\n",
      "220 [D loss real: 0.162845] [D loss fake: 0.413388] [D loss: 0.576233] [G loss: 1.823875]\n",
      "221 [D loss real: 0.116879] [D loss fake: 0.408810] [D loss: 0.525688] [G loss: 1.852919]\n",
      "222 [D loss real: 0.259471] [D loss fake: 0.452336] [D loss: 0.711807] [G loss: 1.763392]\n",
      "223 [D loss real: 0.125578] [D loss fake: 0.431039] [D loss: 0.556618] [G loss: 1.671596]\n",
      "./dataset_2018_05_16/2/\n",
      "224 [D loss real: 0.246370] [D loss fake: 0.416267] [D loss: 0.662636] [G loss: 1.755332]\n",
      "225 [D loss real: 0.157740] [D loss fake: 0.428408] [D loss: 0.586149] [G loss: 1.838562]\n",
      "226 [D loss real: 0.193535] [D loss fake: 0.437575] [D loss: 0.631110] [G loss: 1.748728]\n",
      "227 [D loss real: 0.251881] [D loss fake: 0.409786] [D loss: 0.661667] [G loss: 1.818789]\n",
      "228 [D loss real: 0.195489] [D loss fake: 0.415290] [D loss: 0.610779] [G loss: 1.839865]\n",
      "229 [D loss real: 0.148801] [D loss fake: 0.432632] [D loss: 0.581433] [G loss: 1.794877]\n",
      "230 [D loss real: 0.295671] [D loss fake: 0.405240] [D loss: 0.700911] [G loss: 1.908712]\n",
      "231 [D loss real: 0.155908] [D loss fake: 0.424783] [D loss: 0.580691] [G loss: 1.887524]\n",
      "232 [D loss real: 0.183318] [D loss fake: 0.430010] [D loss: 0.613329] [G loss: 1.757079]\n",
      "233 [D loss real: 0.082788] [D loss fake: 0.455349] [D loss: 0.538137] [G loss: 1.614624]\n",
      "234 [D loss real: 0.169627] [D loss fake: 0.446666] [D loss: 0.616293] [G loss: 1.715494]\n",
      "235 [D loss real: 0.135643] [D loss fake: 0.423843] [D loss: 0.559486] [G loss: 1.821366]\n",
      "236 [D loss real: 0.271998] [D loss fake: 0.428913] [D loss: 0.700912] [G loss: 1.890644]\n",
      "237 [D loss real: 0.259483] [D loss fake: 0.436478] [D loss: 0.695961] [G loss: 1.827981]\n",
      "./dataset_2018_05_16/3/\n",
      "238 [D loss real: 0.247591] [D loss fake: 0.381771] [D loss: 0.629361] [G loss: 1.919060]\n",
      "239 [D loss real: 0.287234] [D loss fake: 0.396731] [D loss: 0.683966] [G loss: 1.833703]\n",
      "240 [D loss real: 0.158672] [D loss fake: 0.447575] [D loss: 0.606246] [G loss: 1.682701]\n",
      "241 [D loss real: 0.143533] [D loss fake: 0.434693] [D loss: 0.578226] [G loss: 1.748787]\n",
      "242 [D loss real: 0.208555] [D loss fake: 0.444538] [D loss: 0.653093] [G loss: 1.754718]\n",
      "243 [D loss real: 0.182616] [D loss fake: 0.420154] [D loss: 0.602770] [G loss: 1.815377]\n",
      "244 [D loss real: 0.106932] [D loss fake: 0.439738] [D loss: 0.546670] [G loss: 1.660921]\n",
      "245 [D loss real: 0.219895] [D loss fake: 0.416729] [D loss: 0.636624] [G loss: 1.847559]\n",
      "246 [D loss real: 0.279181] [D loss fake: 0.454283] [D loss: 0.733464] [G loss: 1.849701]\n",
      "247 [D loss real: 0.247326] [D loss fake: 0.404975] [D loss: 0.652301] [G loss: 1.812420]\n",
      "248 [D loss real: 0.249947] [D loss fake: 0.432116] [D loss: 0.682063] [G loss: 1.825564]\n",
      "249 [D loss real: 0.233788] [D loss fake: 0.440934] [D loss: 0.674722] [G loss: 1.762057]\n",
      "250 [D loss real: 0.141833] [D loss fake: 0.445642] [D loss: 0.587475] [G loss: 1.704883]\n",
      "251 [D loss real: 0.271116] [D loss fake: 0.433269] [D loss: 0.704385] [G loss: 1.816442]\n",
      "./dataset_2018_05_16/4/\n",
      "252 [D loss real: 0.188808] [D loss fake: 0.409378] [D loss: 0.598186] [G loss: 1.793820]\n",
      "253 [D loss real: 0.242749] [D loss fake: 0.444238] [D loss: 0.686987] [G loss: 1.788411]\n",
      "254 [D loss real: 0.231009] [D loss fake: 0.454815] [D loss: 0.685824] [G loss: 1.577002]\n",
      "255 [D loss real: 0.176552] [D loss fake: 0.415266] [D loss: 0.591818] [G loss: 1.892240]\n",
      "256 [D loss real: 0.109786] [D loss fake: 0.405906] [D loss: 0.515692] [G loss: 1.976423]\n",
      "257 [D loss real: 0.226629] [D loss fake: 0.430735] [D loss: 0.657363] [G loss: 1.883148]\n",
      "258 [D loss real: 0.259496] [D loss fake: 0.416858] [D loss: 0.676354] [G loss: 1.884958]\n",
      "259 [D loss real: 0.160930] [D loss fake: 0.435683] [D loss: 0.596613] [G loss: 1.781655]\n",
      "260 [D loss real: 0.130602] [D loss fake: 0.422700] [D loss: 0.553302] [G loss: 1.746380]\n",
      "261 [D loss real: 0.162056] [D loss fake: 0.414713] [D loss: 0.576769] [G loss: 1.788696]\n",
      "262 [D loss real: 0.220830] [D loss fake: 0.443883] [D loss: 0.664714] [G loss: 1.751526]\n",
      "263 [D loss real: 0.155380] [D loss fake: 0.448433] [D loss: 0.603813] [G loss: 1.655757]\n",
      "264 [D loss real: 0.305739] [D loss fake: 0.433020] [D loss: 0.738759] [G loss: 1.831913]\n",
      "265 [D loss real: 0.214553] [D loss fake: 0.428035] [D loss: 0.642588] [G loss: 1.835153]\n",
      "./dataset_2018_05_16/5/\n",
      "266 [D loss real: 0.205131] [D loss fake: 0.414549] [D loss: 0.619680] [G loss: 1.769233]\n",
      "267 [D loss real: 0.225910] [D loss fake: 0.411563] [D loss: 0.637473] [G loss: 1.825612]\n",
      "268 [D loss real: 0.198515] [D loss fake: 0.428442] [D loss: 0.626957] [G loss: 1.856707]\n",
      "269 [D loss real: 0.150004] [D loss fake: 0.426648] [D loss: 0.576652] [G loss: 1.754002]\n",
      "270 [D loss real: 0.263411] [D loss fake: 0.408896] [D loss: 0.672307] [G loss: 1.913589]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271 [D loss real: 0.171846] [D loss fake: 0.421519] [D loss: 0.593365] [G loss: 1.883485]\n",
      "272 [D loss real: 0.251832] [D loss fake: 0.405866] [D loss: 0.657699] [G loss: 1.868368]\n",
      "273 [D loss real: 0.217378] [D loss fake: 0.413606] [D loss: 0.630984] [G loss: 1.790740]\n",
      "274 [D loss real: 0.225751] [D loss fake: 0.443649] [D loss: 0.669400] [G loss: 1.729489]\n",
      "275 [D loss real: 0.171717] [D loss fake: 0.439050] [D loss: 0.610767] [G loss: 1.669594]\n",
      "276 [D loss real: 0.273291] [D loss fake: 0.448368] [D loss: 0.721659] [G loss: 1.718395]\n",
      "277 [D loss real: 0.193608] [D loss fake: 0.416055] [D loss: 0.609663] [G loss: 1.736082]\n",
      "278 [D loss real: 0.228600] [D loss fake: 0.407692] [D loss: 0.636292] [G loss: 1.745156]\n",
      "279 [D loss real: 0.213038] [D loss fake: 0.413550] [D loss: 0.626587] [G loss: 1.915641]\n",
      "./dataset_2018_05_16/6/\n",
      "280 [D loss real: 0.277756] [D loss fake: 0.408176] [D loss: 0.685933] [G loss: 1.906427]\n",
      "281 [D loss real: 0.163184] [D loss fake: 0.446187] [D loss: 0.609371] [G loss: 1.815424]\n",
      "282 [D loss real: 0.204261] [D loss fake: 0.456389] [D loss: 0.660650] [G loss: 1.655240]\n",
      "283 [D loss real: 0.161579] [D loss fake: 0.531464] [D loss: 0.693043] [G loss: 5.872906]\n",
      "284 [D loss real: 0.119176] [D loss fake: 0.915645] [D loss: 1.034821] [G loss: 0.722551]\n",
      "285 [D loss real: 0.191783] [D loss fake: 2.026856] [D loss: 2.218639] [G loss: 6.010432]\n",
      "286 [D loss real: 0.128158] [D loss fake: 1.151321] [D loss: 1.279479] [G loss: 6.360648]\n",
      "287 [D loss real: 0.144168] [D loss fake: 1.090647] [D loss: 1.234816] [G loss: 5.204189]\n",
      "288 [D loss real: 0.157462] [D loss fake: 0.752685] [D loss: 0.910146] [G loss: 4.039591]\n",
      "289 [D loss real: 0.141758] [D loss fake: 0.681424] [D loss: 0.823183] [G loss: 2.902156]\n",
      "290 [D loss real: 0.226792] [D loss fake: 0.433713] [D loss: 0.660505] [G loss: 2.201328]\n",
      "291 [D loss real: 0.315559] [D loss fake: 0.424895] [D loss: 0.740454] [G loss: 1.924872]\n",
      "292 [D loss real: 0.228530] [D loss fake: 0.434085] [D loss: 0.662615] [G loss: 1.718889]\n",
      "293 [D loss real: 0.238065] [D loss fake: 0.428361] [D loss: 0.666426] [G loss: 1.725869]\n",
      "./dataset_2018_05_16/7/\n",
      "294 [D loss real: 0.291918] [D loss fake: 0.475918] [D loss: 0.767836] [G loss: 1.636789]\n",
      "295 [D loss real: 0.241936] [D loss fake: 0.427579] [D loss: 0.669515] [G loss: 1.728090]\n",
      "296 [D loss real: 0.188220] [D loss fake: 0.412720] [D loss: 0.600940] [G loss: 1.847831]\n",
      "297 [D loss real: 0.125133] [D loss fake: 0.405454] [D loss: 0.530587] [G loss: 1.925605]\n",
      "298 [D loss real: 0.281562] [D loss fake: 0.446734] [D loss: 0.728296] [G loss: 1.842609]\n",
      "299 [D loss real: 0.322583] [D loss fake: 0.416574] [D loss: 0.739157] [G loss: 1.788255]\n",
      "300 [D loss real: 0.241477] [D loss fake: 0.414608] [D loss: 0.656085] [G loss: 1.776276]\n",
      "301 [D loss real: 0.233703] [D loss fake: 0.420431] [D loss: 0.654135] [G loss: 1.769293]\n",
      "302 [D loss real: 0.252749] [D loss fake: 0.419060] [D loss: 0.671810] [G loss: 1.817909]\n",
      "303 [D loss real: 0.084591] [D loss fake: 0.419996] [D loss: 0.504587] [G loss: 1.830003]\n",
      "304 [D loss real: 0.126250] [D loss fake: 0.388684] [D loss: 0.514934] [G loss: 1.905206]\n",
      "305 [D loss real: 0.156188] [D loss fake: 0.434261] [D loss: 0.590448] [G loss: 1.844538]\n",
      "306 [D loss real: 0.137279] [D loss fake: 0.403826] [D loss: 0.541105] [G loss: 1.852448]\n",
      "307 [D loss real: 0.201697] [D loss fake: 0.426316] [D loss: 0.628013] [G loss: 1.841348]\n",
      "308 [D loss real: 0.190064] [D loss fake: 0.454743] [D loss: 0.644807] [G loss: 1.744133]\n",
      "./dataset_2018_05_16/8/\n",
      "309 [D loss real: 0.216218] [D loss fake: 0.416182] [D loss: 0.632401] [G loss: 1.733595]\n",
      "310 [D loss real: 0.106280] [D loss fake: 0.432726] [D loss: 0.539006] [G loss: 1.774304]\n",
      "311 [D loss real: 0.210735] [D loss fake: 0.390559] [D loss: 0.601294] [G loss: 1.843873]\n",
      "312 [D loss real: 0.219787] [D loss fake: 0.429449] [D loss: 0.649236] [G loss: 1.831842]\n",
      "313 [D loss real: 0.203413] [D loss fake: 0.392042] [D loss: 0.595456] [G loss: 1.887324]\n",
      "314 [D loss real: 0.140580] [D loss fake: 0.409622] [D loss: 0.550202] [G loss: 1.897916]\n",
      "315 [D loss real: 0.234145] [D loss fake: 0.431552] [D loss: 0.665696] [G loss: 1.804710]\n",
      "316 [D loss real: 0.218788] [D loss fake: 0.449461] [D loss: 0.668249] [G loss: 1.779787]\n",
      "317 [D loss real: 0.232437] [D loss fake: 0.429684] [D loss: 0.662121] [G loss: 1.736594]\n",
      "318 [D loss real: 0.242726] [D loss fake: 0.455585] [D loss: 0.698311] [G loss: 1.701520]\n",
      "319 [D loss real: 0.255141] [D loss fake: 0.466136] [D loss: 0.721277] [G loss: 1.720178]\n",
      "320 [D loss real: 0.313008] [D loss fake: 0.417348] [D loss: 0.730356] [G loss: 1.756011]\n",
      "321 [D loss real: 0.289157] [D loss fake: 0.390302] [D loss: 0.679459] [G loss: 1.835895]\n",
      "322 [D loss real: 0.234070] [D loss fake: 0.432198] [D loss: 0.666268] [G loss: 1.885910]\n",
      "./dataset_2018_05_16/9/\n",
      "323 [D loss real: 0.193617] [D loss fake: 0.428473] [D loss: 0.622090] [G loss: 1.826542]\n",
      "324 [D loss real: 0.217968] [D loss fake: 0.428750] [D loss: 0.646718] [G loss: 1.804654]\n",
      "325 [D loss real: 0.216624] [D loss fake: 0.412683] [D loss: 0.629307] [G loss: 1.855749]\n",
      "326 [D loss real: 0.352264] [D loss fake: 0.435392] [D loss: 0.787656] [G loss: 1.840117]\n",
      "327 [D loss real: 0.287874] [D loss fake: 0.438331] [D loss: 0.726205] [G loss: 1.780562]\n",
      "328 [D loss real: 0.189420] [D loss fake: 0.447450] [D loss: 0.636870] [G loss: 1.787152]\n",
      "329 [D loss real: 0.239376] [D loss fake: 0.431058] [D loss: 0.670433] [G loss: 1.737805]\n",
      "330 [D loss real: 0.293218] [D loss fake: 0.456937] [D loss: 0.750155] [G loss: 1.695992]\n",
      "331 [D loss real: 0.180133] [D loss fake: 0.436910] [D loss: 0.617043] [G loss: 1.763941]\n",
      "332 [D loss real: 0.222387] [D loss fake: 0.440065] [D loss: 0.662451] [G loss: 1.719052]\n",
      "333 [D loss real: 0.200205] [D loss fake: 0.427011] [D loss: 0.627216] [G loss: 1.799761]\n",
      "334 [D loss real: 0.263356] [D loss fake: 0.415073] [D loss: 0.678429] [G loss: 1.816792]\n",
      "335 [D loss real: 0.190525] [D loss fake: 0.393732] [D loss: 0.584257] [G loss: 1.879098]\n",
      "336 [D loss real: 0.244210] [D loss fake: 0.441179] [D loss: 0.685389] [G loss: 1.841205]\n",
      "./dataset_2018_05_16/10/\n",
      "337 [D loss real: 0.126950] [D loss fake: 0.401386] [D loss: 0.528336] [G loss: 1.825000]\n",
      "338 [D loss real: 0.183291] [D loss fake: 0.435844] [D loss: 0.619135] [G loss: 1.807781]\n",
      "339 [D loss real: 0.110372] [D loss fake: 0.440439] [D loss: 0.550811] [G loss: 1.742397]\n",
      "340 [D loss real: 0.203607] [D loss fake: 0.418111] [D loss: 0.621719] [G loss: 1.778886]\n",
      "341 [D loss real: 0.213756] [D loss fake: 0.441437] [D loss: 0.655193] [G loss: 1.746137]\n",
      "342 [D loss real: 0.214294] [D loss fake: 0.451842] [D loss: 0.666135] [G loss: 1.705083]\n",
      "343 [D loss real: 0.113405] [D loss fake: 0.404846] [D loss: 0.518251] [G loss: 1.824022]\n",
      "344 [D loss real: 0.084940] [D loss fake: 0.450657] [D loss: 0.535597] [G loss: 1.748351]\n",
      "345 [D loss real: 0.190377] [D loss fake: 0.426688] [D loss: 0.617065] [G loss: 1.738604]\n",
      "346 [D loss real: 0.240095] [D loss fake: 0.429331] [D loss: 0.669426] [G loss: 1.830293]\n",
      "347 [D loss real: 0.144967] [D loss fake: 0.370117] [D loss: 0.515084] [G loss: 1.823629]\n",
      "348 [D loss real: 0.307789] [D loss fake: 0.407535] [D loss: 0.715324] [G loss: 1.936245]\n",
      "349 [D loss real: 0.156244] [D loss fake: 0.433994] [D loss: 0.590238] [G loss: 1.858220]\n",
      "350 [D loss real: 0.158492] [D loss fake: 0.448070] [D loss: 0.606562] [G loss: 1.783899]\n",
      "./dataset_2018_05_16/11/\n",
      "351 [D loss real: 0.289612] [D loss fake: 0.411221] [D loss: 0.700833] [G loss: 1.796901]\n",
      "352 [D loss real: 0.419073] [D loss fake: 0.398635] [D loss: 0.817708] [G loss: 2.091388]\n",
      "353 [D loss real: 0.300286] [D loss fake: 0.449976] [D loss: 0.750263] [G loss: 2.005258]\n",
      "354 [D loss real: 0.269934] [D loss fake: 0.414563] [D loss: 0.684497] [G loss: 1.835933]\n",
      "355 [D loss real: 0.215846] [D loss fake: 0.437029] [D loss: 0.652875] [G loss: 1.760978]\n",
      "356 [D loss real: 0.260987] [D loss fake: 0.418975] [D loss: 0.679962] [G loss: 1.795213]\n",
      "357 [D loss real: 0.220601] [D loss fake: 0.434990] [D loss: 0.655591] [G loss: 1.787393]\n",
      "358 [D loss real: 0.119801] [D loss fake: 0.425481] [D loss: 0.545282] [G loss: 1.805745]\n",
      "359 [D loss real: 0.112958] [D loss fake: 0.423087] [D loss: 0.536044] [G loss: 1.797756]\n",
      "360 [D loss real: 0.218850] [D loss fake: 0.425768] [D loss: 0.644618] [G loss: 1.850150]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361 [D loss real: 0.186129] [D loss fake: 0.429298] [D loss: 0.615427] [G loss: 1.837809]\n",
      "362 [D loss real: 0.178223] [D loss fake: 0.408608] [D loss: 0.586831] [G loss: 1.864512]\n",
      "363 [D loss real: 0.125493] [D loss fake: 0.402630] [D loss: 0.528122] [G loss: 1.813225]\n",
      "364 [D loss real: 0.247684] [D loss fake: 0.413382] [D loss: 0.661066] [G loss: 1.888912]\n",
      "./dataset_2018_05_16/12/\n",
      "365 [D loss real: 0.258208] [D loss fake: 0.411752] [D loss: 0.669960] [G loss: 1.819908]\n",
      "366 [D loss real: 0.163259] [D loss fake: 0.380111] [D loss: 0.543370] [G loss: 1.870308]\n",
      "367 [D loss real: 0.258799] [D loss fake: 0.430624] [D loss: 0.689424] [G loss: 1.876582]\n",
      "368 [D loss real: 0.198730] [D loss fake: 0.459046] [D loss: 0.657776] [G loss: 1.770318]\n",
      "369 [D loss real: 0.161758] [D loss fake: 0.433414] [D loss: 0.595171] [G loss: 1.768187]\n",
      "370 [D loss real: 0.287004] [D loss fake: 0.455166] [D loss: 0.742171] [G loss: 1.709686]\n",
      "371 [D loss real: 0.182542] [D loss fake: 0.429115] [D loss: 0.611657] [G loss: 1.707542]\n",
      "372 [D loss real: 0.227536] [D loss fake: 0.435506] [D loss: 0.663042] [G loss: 1.820557]\n",
      "373 [D loss real: 0.225117] [D loss fake: 0.402573] [D loss: 0.627690] [G loss: 1.799855]\n",
      "374 [D loss real: 0.090986] [D loss fake: 0.441085] [D loss: 0.532071] [G loss: 1.845876]\n",
      "375 [D loss real: 0.102858] [D loss fake: 0.428993] [D loss: 0.531851] [G loss: 1.775958]\n",
      "376 [D loss real: 0.201023] [D loss fake: 0.400915] [D loss: 0.601938] [G loss: 1.803068]\n",
      "377 [D loss real: 0.304029] [D loss fake: 0.396355] [D loss: 0.700384] [G loss: 1.855635]\n",
      "378 [D loss real: 0.117880] [D loss fake: 0.448269] [D loss: 0.566149] [G loss: 1.763630]\n",
      "./dataset_2018_05_16/13/\n",
      "379 [D loss real: 0.179726] [D loss fake: 0.436757] [D loss: 0.616483] [G loss: 1.774761]\n",
      "380 [D loss real: 0.162003] [D loss fake: 0.399734] [D loss: 0.561736] [G loss: 1.795971]\n",
      "381 [D loss real: 0.248802] [D loss fake: 0.430983] [D loss: 0.679785] [G loss: 1.829882]\n",
      "382 [D loss real: 0.221568] [D loss fake: 0.410623] [D loss: 0.632191] [G loss: 1.832240]\n",
      "383 [D loss real: 0.106671] [D loss fake: 0.439914] [D loss: 0.546586] [G loss: 1.820812]\n",
      "384 [D loss real: 0.126435] [D loss fake: 0.389458] [D loss: 0.515893] [G loss: 1.851812]\n",
      "385 [D loss real: 0.229789] [D loss fake: 0.433725] [D loss: 0.663515] [G loss: 1.881346]\n",
      "386 [D loss real: 0.117454] [D loss fake: 0.442646] [D loss: 0.560101] [G loss: 1.779265]\n",
      "387 [D loss real: 0.213203] [D loss fake: 0.418027] [D loss: 0.631230] [G loss: 1.790217]\n",
      "388 [D loss real: 0.290061] [D loss fake: 0.434826] [D loss: 0.724886] [G loss: 1.773130]\n",
      "389 [D loss real: 0.200825] [D loss fake: 0.418718] [D loss: 0.619542] [G loss: 1.763886]\n",
      "390 [D loss real: 0.210057] [D loss fake: 0.408587] [D loss: 0.618644] [G loss: 1.819559]\n",
      "391 [D loss real: 0.241204] [D loss fake: 0.420538] [D loss: 0.661742] [G loss: 1.881861]\n",
      "392 [D loss real: 0.101913] [D loss fake: 0.394167] [D loss: 0.496080] [G loss: 1.872771]\n",
      "./dataset_2018_05_16/14/\n",
      "393 [D loss real: 0.182039] [D loss fake: 0.426960] [D loss: 0.608999] [G loss: 1.861283]\n",
      "394 [D loss real: 0.176403] [D loss fake: 0.379934] [D loss: 0.556338] [G loss: 1.862022]\n",
      "395 [D loss real: 0.164721] [D loss fake: 0.417319] [D loss: 0.582040] [G loss: 1.906931]\n",
      "396 [D loss real: 0.129664] [D loss fake: 0.449013] [D loss: 0.578677] [G loss: 1.762444]\n",
      "397 [D loss real: 0.152410] [D loss fake: 0.430903] [D loss: 0.583313] [G loss: 1.763388]\n",
      "398 [D loss real: 0.272174] [D loss fake: 0.432889] [D loss: 0.705062] [G loss: 1.766574]\n",
      "399 [D loss real: 0.066565] [D loss fake: 0.430862] [D loss: 0.497427] [G loss: 1.759433]\n",
      "400 [D loss real: 0.183198] [D loss fake: 0.436639] [D loss: 0.619837] [G loss: 1.731537]\n",
      "401 [D loss real: 0.229750] [D loss fake: 0.432531] [D loss: 0.662281] [G loss: 1.804399]\n",
      "402 [D loss real: 0.217699] [D loss fake: 0.429119] [D loss: 0.646818] [G loss: 1.814807]\n",
      "403 [D loss real: 0.224566] [D loss fake: 0.428565] [D loss: 0.653130] [G loss: 1.757113]\n",
      "404 [D loss real: 0.151365] [D loss fake: 0.403492] [D loss: 0.554857] [G loss: 1.788163]\n",
      "405 [D loss real: 0.219855] [D loss fake: 0.419687] [D loss: 0.639543] [G loss: 1.794984]\n",
      "406 [D loss real: 0.270517] [D loss fake: 0.446961] [D loss: 0.717478] [G loss: 1.780687]\n",
      "./dataset_2018_05_16/15/\n",
      "407 [D loss real: 0.168901] [D loss fake: 0.407590] [D loss: 0.576491] [G loss: 1.803597]\n",
      "408 [D loss real: 0.199930] [D loss fake: 0.420070] [D loss: 0.620000] [G loss: 1.806352]\n",
      "409 [D loss real: 0.188892] [D loss fake: 0.442034] [D loss: 0.630926] [G loss: 1.792233]\n",
      "410 [D loss real: 0.125257] [D loss fake: 0.411292] [D loss: 0.536549] [G loss: 1.813202]\n",
      "411 [D loss real: 0.117027] [D loss fake: 0.415524] [D loss: 0.532551] [G loss: 1.848942]\n",
      "412 [D loss real: 0.177432] [D loss fake: 0.439767] [D loss: 0.617199] [G loss: 1.775946]\n",
      "413 [D loss real: 0.216946] [D loss fake: 0.418870] [D loss: 0.635816] [G loss: 1.758467]\n",
      "414 [D loss real: 0.244943] [D loss fake: 0.453602] [D loss: 0.698545] [G loss: 1.751115]\n",
      "415 [D loss real: 0.177410] [D loss fake: 0.447844] [D loss: 0.625254] [G loss: 1.694221]\n",
      "416 [D loss real: 0.299621] [D loss fake: 0.426867] [D loss: 0.726488] [G loss: 1.801668]\n",
      "417 [D loss real: 0.159591] [D loss fake: 0.409011] [D loss: 0.568603] [G loss: 1.809701]\n",
      "418 [D loss real: 0.312903] [D loss fake: 0.424080] [D loss: 0.736984] [G loss: 1.823855]\n",
      "419 [D loss real: 0.190591] [D loss fake: 0.428194] [D loss: 0.618785] [G loss: 1.774586]\n",
      "420 [D loss real: 0.206005] [D loss fake: 0.422803] [D loss: 0.628808] [G loss: 1.819137]\n",
      "./dataset_2018_05_16/1/\n",
      "421 [D loss real: 0.200563] [D loss fake: 0.409464] [D loss: 0.610027] [G loss: 1.811380]\n",
      "422 [D loss real: 0.096481] [D loss fake: 0.419794] [D loss: 0.516276] [G loss: 1.881317]\n",
      "423 [D loss real: 0.209133] [D loss fake: 0.411970] [D loss: 0.621103] [G loss: 1.887950]\n",
      "424 [D loss real: 0.264280] [D loss fake: 0.450231] [D loss: 0.714511] [G loss: 1.777557]\n",
      "425 [D loss real: 0.197385] [D loss fake: 0.415952] [D loss: 0.613338] [G loss: 1.741309]\n",
      "426 [D loss real: 0.231356] [D loss fake: 0.421561] [D loss: 0.652917] [G loss: 1.806289]\n",
      "427 [D loss real: 0.169511] [D loss fake: 0.412005] [D loss: 0.581516] [G loss: 1.806618]\n",
      "428 [D loss real: 0.213382] [D loss fake: 0.416096] [D loss: 0.629478] [G loss: 1.880025]\n",
      "429 [D loss real: 0.287811] [D loss fake: 0.399348] [D loss: 0.687159] [G loss: 1.858621]\n",
      "430 [D loss real: 0.184968] [D loss fake: 0.438019] [D loss: 0.622987] [G loss: 1.835813]\n",
      "431 [D loss real: 0.194397] [D loss fake: 0.401599] [D loss: 0.595996] [G loss: 1.865968]\n",
      "432 [D loss real: 0.261251] [D loss fake: 0.381829] [D loss: 0.643080] [G loss: 1.896877]\n",
      "433 [D loss real: 0.252807] [D loss fake: 0.441783] [D loss: 0.694591] [G loss: 1.850361]\n",
      "434 [D loss real: 0.249552] [D loss fake: 0.377839] [D loss: 0.627391] [G loss: 1.850658]\n",
      "./dataset_2018_05_16/2/\n",
      "435 [D loss real: 0.149559] [D loss fake: 0.375423] [D loss: 0.524982] [G loss: 2.011473]\n",
      "436 [D loss real: 0.238190] [D loss fake: 0.439305] [D loss: 0.677495] [G loss: 1.891081]\n",
      "437 [D loss real: 0.273184] [D loss fake: 0.436014] [D loss: 0.709198] [G loss: 1.767426]\n",
      "438 [D loss real: 0.174144] [D loss fake: 0.444308] [D loss: 0.618452] [G loss: 1.710676]\n",
      "439 [D loss real: 0.125648] [D loss fake: 0.414120] [D loss: 0.539768] [G loss: 1.812271]\n",
      "440 [D loss real: 0.191093] [D loss fake: 0.413138] [D loss: 0.604231] [G loss: 1.799699]\n",
      "441 [D loss real: 0.245255] [D loss fake: 0.459725] [D loss: 0.704979] [G loss: 1.789402]\n",
      "442 [D loss real: 0.097270] [D loss fake: 0.445576] [D loss: 0.542846] [G loss: 1.723122]\n",
      "443 [D loss real: 0.230551] [D loss fake: 0.437830] [D loss: 0.668381] [G loss: 1.745269]\n",
      "444 [D loss real: 0.125011] [D loss fake: 0.429929] [D loss: 0.554940] [G loss: 1.788898]\n",
      "445 [D loss real: 0.209295] [D loss fake: 0.421786] [D loss: 0.631081] [G loss: 1.730187]\n",
      "446 [D loss real: 0.196897] [D loss fake: 0.428422] [D loss: 0.625319] [G loss: 1.763541]\n",
      "447 [D loss real: 0.239795] [D loss fake: 0.392531] [D loss: 0.632327] [G loss: 1.809148]\n",
      "448 [D loss real: 0.164097] [D loss fake: 0.419892] [D loss: 0.583989] [G loss: 1.885777]\n",
      "./dataset_2018_05_16/3/\n",
      "449 [D loss real: 0.177662] [D loss fake: 0.418083] [D loss: 0.595745] [G loss: 1.833077]\n",
      "450 [D loss real: 0.267915] [D loss fake: 0.419492] [D loss: 0.687407] [G loss: 1.872823]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "451 [D loss real: 0.274045] [D loss fake: 0.452715] [D loss: 0.726760] [G loss: 1.761240]\n",
      "452 [D loss real: 0.195361] [D loss fake: 0.390430] [D loss: 0.585791] [G loss: 1.832733]\n",
      "453 [D loss real: 0.162430] [D loss fake: 0.436847] [D loss: 0.599277] [G loss: 1.899368]\n",
      "454 [D loss real: 0.258938] [D loss fake: 0.406109] [D loss: 0.665047] [G loss: 1.805015]\n",
      "455 [D loss real: 0.223285] [D loss fake: 0.423513] [D loss: 0.646798] [G loss: 1.864162]\n",
      "456 [D loss real: 0.176534] [D loss fake: 0.459986] [D loss: 0.636520] [G loss: 1.790888]\n",
      "457 [D loss real: 0.205289] [D loss fake: 0.433976] [D loss: 0.639265] [G loss: 1.717239]\n",
      "458 [D loss real: 0.208206] [D loss fake: 0.452908] [D loss: 0.661115] [G loss: 1.731920]\n",
      "459 [D loss real: 0.253184] [D loss fake: 0.454018] [D loss: 0.707201] [G loss: 1.709167]\n",
      "460 [D loss real: 0.241541] [D loss fake: 0.404366] [D loss: 0.645907] [G loss: 1.788247]\n",
      "461 [D loss real: 0.139698] [D loss fake: 0.411783] [D loss: 0.551481] [G loss: 1.824886]\n",
      "462 [D loss real: 0.175143] [D loss fake: 0.436349] [D loss: 0.611492] [G loss: 1.868402]\n",
      "./dataset_2018_05_16/4/\n",
      "463 [D loss real: 0.287171] [D loss fake: 0.411764] [D loss: 0.698935] [G loss: 1.790649]\n",
      "464 [D loss real: 0.292751] [D loss fake: 0.406452] [D loss: 0.699203] [G loss: 1.816547]\n",
      "465 [D loss real: 0.161059] [D loss fake: 0.431076] [D loss: 0.592134] [G loss: 1.839527]\n",
      "466 [D loss real: 0.224343] [D loss fake: 0.438021] [D loss: 0.662363] [G loss: 1.777494]\n",
      "467 [D loss real: 0.162006] [D loss fake: 0.433010] [D loss: 0.595016] [G loss: 1.778727]\n",
      "468 [D loss real: 0.209657] [D loss fake: 0.425900] [D loss: 0.635557] [G loss: 1.760043]\n",
      "469 [D loss real: 0.263963] [D loss fake: 0.397928] [D loss: 0.661891] [G loss: 1.839607]\n",
      "470 [D loss real: 0.095471] [D loss fake: 0.417020] [D loss: 0.512491] [G loss: 1.871606]\n",
      "471 [D loss real: 0.093248] [D loss fake: 0.447531] [D loss: 0.540779] [G loss: 1.870638]\n",
      "472 [D loss real: 0.223245] [D loss fake: 0.406062] [D loss: 0.629307] [G loss: 1.746834]\n",
      "473 [D loss real: 0.219853] [D loss fake: 0.422249] [D loss: 0.642102] [G loss: 1.817771]\n",
      "474 [D loss real: 0.249413] [D loss fake: 0.428456] [D loss: 0.677869] [G loss: 1.767828]\n",
      "475 [D loss real: 0.227784] [D loss fake: 0.423951] [D loss: 0.651735] [G loss: 1.760665]\n",
      "476 [D loss real: 0.185374] [D loss fake: 0.415496] [D loss: 0.600869] [G loss: 1.786743]\n",
      "./dataset_2018_05_16/5/\n",
      "477 [D loss real: 0.221028] [D loss fake: 0.390821] [D loss: 0.611849] [G loss: 1.906733]\n",
      "478 [D loss real: 0.226194] [D loss fake: 0.385529] [D loss: 0.611723] [G loss: 1.925089]\n",
      "479 [D loss real: 0.132603] [D loss fake: 0.468348] [D loss: 0.600951] [G loss: 1.806953]\n",
      "480 [D loss real: 0.209479] [D loss fake: 0.417262] [D loss: 0.626742] [G loss: 1.730599]\n",
      "481 [D loss real: 0.158333] [D loss fake: 0.416384] [D loss: 0.574716] [G loss: 1.791734]\n",
      "482 [D loss real: 0.178094] [D loss fake: 0.433403] [D loss: 0.611497] [G loss: 1.801937]\n",
      "483 [D loss real: 0.275463] [D loss fake: 0.444955] [D loss: 0.720418] [G loss: 1.725026]\n",
      "484 [D loss real: 0.193120] [D loss fake: 0.432231] [D loss: 0.625350] [G loss: 1.752796]\n",
      "485 [D loss real: 0.154402] [D loss fake: 0.443142] [D loss: 0.597544] [G loss: 1.736137]\n",
      "486 [D loss real: 0.241816] [D loss fake: 0.413314] [D loss: 0.655130] [G loss: 1.782757]\n",
      "487 [D loss real: 0.203610] [D loss fake: 0.421519] [D loss: 0.625129] [G loss: 1.784006]\n",
      "488 [D loss real: 0.199674] [D loss fake: 0.405659] [D loss: 0.605333] [G loss: 1.831269]\n",
      "489 [D loss real: 0.235450] [D loss fake: 0.408427] [D loss: 0.643877] [G loss: 1.876608]\n",
      "490 [D loss real: 0.188483] [D loss fake: 0.440296] [D loss: 0.628779] [G loss: 1.899787]\n",
      "./dataset_2018_05_16/6/\n",
      "491 [D loss real: 0.199262] [D loss fake: 0.436113] [D loss: 0.635375] [G loss: 1.753102]\n",
      "492 [D loss real: 0.247015] [D loss fake: 0.430635] [D loss: 0.677650] [G loss: 1.793308]\n",
      "493 [D loss real: 0.198095] [D loss fake: 0.415999] [D loss: 0.614094] [G loss: 1.821282]\n",
      "494 [D loss real: 0.355945] [D loss fake: 0.400069] [D loss: 0.756015] [G loss: 1.832110]\n",
      "495 [D loss real: 0.245734] [D loss fake: 0.434369] [D loss: 0.680103] [G loss: 1.845403]\n",
      "496 [D loss real: 0.209697] [D loss fake: 0.427319] [D loss: 0.637016] [G loss: 1.829098]\n",
      "497 [D loss real: 0.167806] [D loss fake: 0.448609] [D loss: 0.616416] [G loss: 1.826804]\n",
      "498 [D loss real: 0.164021] [D loss fake: 0.398256] [D loss: 0.562277] [G loss: 1.843780]\n",
      "499 [D loss real: 0.177758] [D loss fake: 0.429724] [D loss: 0.607482] [G loss: 1.799690]\n",
      "500 [D loss real: 0.182222] [D loss fake: 0.420652] [D loss: 0.602874] [G loss: 1.801700]\n",
      "gan imaga2 :  (128, 128, 1)\n",
      "501 [D loss real: 0.199030] [D loss fake: 0.418620] [D loss: 0.617650] [G loss: 1.770752]\n",
      "502 [D loss real: 0.253660] [D loss fake: 0.442095] [D loss: 0.695755] [G loss: 1.731429]\n",
      "503 [D loss real: 0.243282] [D loss fake: 0.397347] [D loss: 0.640629] [G loss: 1.860855]\n",
      "504 [D loss real: 0.198919] [D loss fake: 0.446184] [D loss: 0.645103] [G loss: 1.815966]\n",
      "./dataset_2018_05_16/7/\n",
      "505 [D loss real: 0.205386] [D loss fake: 0.426433] [D loss: 0.631819] [G loss: 1.804246]\n",
      "506 [D loss real: 0.051042] [D loss fake: 0.413000] [D loss: 0.464043] [G loss: 1.788544]\n",
      "507 [D loss real: 0.226964] [D loss fake: 0.406675] [D loss: 0.633639] [G loss: 1.877283]\n",
      "508 [D loss real: 0.218819] [D loss fake: 0.435245] [D loss: 0.654065] [G loss: 1.852592]\n",
      "509 [D loss real: 0.246299] [D loss fake: 0.411343] [D loss: 0.657643] [G loss: 1.812643]\n",
      "510 [D loss real: 0.219111] [D loss fake: 0.446704] [D loss: 0.665815] [G loss: 1.812615]\n",
      "511 [D loss real: 0.126173] [D loss fake: 0.415197] [D loss: 0.541370] [G loss: 1.784280]\n",
      "512 [D loss real: 0.097088] [D loss fake: 0.413430] [D loss: 0.510518] [G loss: 1.860545]\n",
      "513 [D loss real: 0.281881] [D loss fake: 0.447718] [D loss: 0.729598] [G loss: 1.704035]\n",
      "514 [D loss real: 0.252637] [D loss fake: 0.401957] [D loss: 0.654594] [G loss: 1.842001]\n",
      "515 [D loss real: 0.139585] [D loss fake: 0.435557] [D loss: 0.575142] [G loss: 1.858399]\n",
      "516 [D loss real: 0.263780] [D loss fake: 0.458449] [D loss: 0.722229] [G loss: 1.745188]\n",
      "517 [D loss real: 0.171253] [D loss fake: 0.447240] [D loss: 0.618494] [G loss: 1.679416]\n",
      "518 [D loss real: 0.232026] [D loss fake: 0.438369] [D loss: 0.670395] [G loss: 1.777881]\n",
      "./dataset_2018_05_16/8/\n",
      "519 [D loss real: 0.282266] [D loss fake: 0.420093] [D loss: 0.702359] [G loss: 1.751795]\n",
      "520 [D loss real: 0.267372] [D loss fake: 0.431790] [D loss: 0.699163] [G loss: 1.774779]\n",
      "521 [D loss real: 0.245260] [D loss fake: 0.455157] [D loss: 0.700418] [G loss: 1.766341]\n",
      "522 [D loss real: 0.171407] [D loss fake: 0.428941] [D loss: 0.600348] [G loss: 1.762947]\n",
      "523 [D loss real: 0.198402] [D loss fake: 0.437683] [D loss: 0.636085] [G loss: 1.802720]\n",
      "524 [D loss real: 0.231085] [D loss fake: 0.429725] [D loss: 0.660810] [G loss: 1.791165]\n",
      "525 [D loss real: 0.067113] [D loss fake: 0.423901] [D loss: 0.491014] [G loss: 1.822149]\n",
      "526 [D loss real: 0.173339] [D loss fake: 0.454434] [D loss: 0.627774] [G loss: 1.747741]\n",
      "527 [D loss real: 0.174765] [D loss fake: 0.444596] [D loss: 0.619361] [G loss: 1.764363]\n",
      "528 [D loss real: 0.221027] [D loss fake: 0.401962] [D loss: 0.622988] [G loss: 1.817453]\n",
      "529 [D loss real: 0.186251] [D loss fake: 0.410350] [D loss: 0.596600] [G loss: 1.849278]\n",
      "530 [D loss real: 0.179062] [D loss fake: 0.416949] [D loss: 0.596010] [G loss: 1.829627]\n",
      "531 [D loss real: 0.090729] [D loss fake: 0.436687] [D loss: 0.527416] [G loss: 1.807752]\n",
      "532 [D loss real: 0.159883] [D loss fake: 0.384908] [D loss: 0.544791] [G loss: 1.870460]\n",
      "./dataset_2018_05_16/9/\n",
      "533 [D loss real: 0.198602] [D loss fake: 0.406304] [D loss: 0.604905] [G loss: 1.859859]\n",
      "534 [D loss real: 0.314927] [D loss fake: 0.431757] [D loss: 0.746684] [G loss: 1.824726]\n",
      "535 [D loss real: 0.203052] [D loss fake: 0.395847] [D loss: 0.598899] [G loss: 1.792923]\n",
      "536 [D loss real: 0.146389] [D loss fake: 0.456722] [D loss: 0.603110] [G loss: 1.768237]\n",
      "537 [D loss real: 0.081526] [D loss fake: 0.402087] [D loss: 0.483614] [G loss: 1.847748]\n",
      "538 [D loss real: 0.241207] [D loss fake: 0.413630] [D loss: 0.654837] [G loss: 1.796687]\n",
      "539 [D loss real: 0.202536] [D loss fake: 0.408759] [D loss: 0.611295] [G loss: 1.859170]\n",
      "540 [D loss real: 0.205151] [D loss fake: 0.412356] [D loss: 0.617507] [G loss: 1.863616]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541 [D loss real: 0.233139] [D loss fake: 0.439275] [D loss: 0.672414] [G loss: 1.719420]\n",
      "542 [D loss real: 0.337755] [D loss fake: 0.408002] [D loss: 0.745757] [G loss: 1.814319]\n",
      "543 [D loss real: 0.215041] [D loss fake: 0.399700] [D loss: 0.614741] [G loss: 1.934950]\n",
      "544 [D loss real: 0.143140] [D loss fake: 0.426330] [D loss: 0.569470] [G loss: 1.797821]\n",
      "545 [D loss real: 0.196812] [D loss fake: 0.439841] [D loss: 0.636653] [G loss: 1.834615]\n",
      "546 [D loss real: 0.121672] [D loss fake: 0.435380] [D loss: 0.557053] [G loss: 1.823989]\n",
      "./dataset_2018_05_16/10/\n",
      "547 [D loss real: 0.185970] [D loss fake: 0.418554] [D loss: 0.604524] [G loss: 1.805066]\n",
      "548 [D loss real: 0.124675] [D loss fake: 0.398503] [D loss: 0.523178] [G loss: 1.860340]\n",
      "549 [D loss real: 0.206566] [D loss fake: 0.414903] [D loss: 0.621469] [G loss: 1.864409]\n",
      "550 [D loss real: 0.122497] [D loss fake: 0.420044] [D loss: 0.542541] [G loss: 1.820511]\n",
      "551 [D loss real: 0.119153] [D loss fake: 0.399562] [D loss: 0.518715] [G loss: 1.890971]\n",
      "552 [D loss real: 0.124429] [D loss fake: 0.443375] [D loss: 0.567804] [G loss: 1.827121]\n",
      "553 [D loss real: 0.273003] [D loss fake: 0.411124] [D loss: 0.684127] [G loss: 1.760647]\n",
      "554 [D loss real: 0.248996] [D loss fake: 0.401906] [D loss: 0.650902] [G loss: 1.861932]\n",
      "555 [D loss real: 0.196335] [D loss fake: 0.420614] [D loss: 0.616949] [G loss: 1.884860]\n",
      "556 [D loss real: 0.233820] [D loss fake: 0.473904] [D loss: 0.707725] [G loss: 1.739343]\n",
      "557 [D loss real: 0.282075] [D loss fake: 0.460074] [D loss: 0.742149] [G loss: 1.620426]\n",
      "558 [D loss real: 0.254749] [D loss fake: 0.443558] [D loss: 0.698308] [G loss: 1.696497]\n",
      "559 [D loss real: 0.183089] [D loss fake: 0.434207] [D loss: 0.617296] [G loss: 1.772232]\n",
      "560 [D loss real: 0.209062] [D loss fake: 0.443652] [D loss: 0.652714] [G loss: 1.825522]\n",
      "561 [D loss real: 0.272639] [D loss fake: 0.436555] [D loss: 0.709193] [G loss: 1.730328]\n",
      "./dataset_2018_05_16/11/\n",
      "562 [D loss real: 0.209654] [D loss fake: 0.417885] [D loss: 0.627540] [G loss: 1.794874]\n",
      "563 [D loss real: 0.214807] [D loss fake: 0.359994] [D loss: 0.574801] [G loss: 2.133156]\n",
      "564 [D loss real: 0.246027] [D loss fake: 0.429432] [D loss: 0.675459] [G loss: 1.993626]\n",
      "565 [D loss real: 0.333256] [D loss fake: 0.448727] [D loss: 0.781982] [G loss: 1.756718]\n",
      "566 [D loss real: 0.190241] [D loss fake: 0.420307] [D loss: 0.610549] [G loss: 1.764665]\n",
      "567 [D loss real: 0.281431] [D loss fake: 0.430782] [D loss: 0.712213] [G loss: 1.779252]\n",
      "568 [D loss real: 0.199160] [D loss fake: 0.435202] [D loss: 0.634361] [G loss: 1.752333]\n",
      "569 [D loss real: 0.130723] [D loss fake: 0.430346] [D loss: 0.561068] [G loss: 1.750340]\n",
      "570 [D loss real: 0.138849] [D loss fake: 0.431324] [D loss: 0.570173] [G loss: 1.812074]\n",
      "571 [D loss real: 0.226541] [D loss fake: 0.396189] [D loss: 0.622731] [G loss: 1.859809]\n",
      "572 [D loss real: 0.160244] [D loss fake: 0.394779] [D loss: 0.555023] [G loss: 1.921052]\n",
      "573 [D loss real: 0.192066] [D loss fake: 0.447817] [D loss: 0.639883] [G loss: 1.865612]\n",
      "574 [D loss real: 0.202154] [D loss fake: 0.398010] [D loss: 0.600163] [G loss: 1.802209]\n",
      "575 [D loss real: 0.161922] [D loss fake: 0.428219] [D loss: 0.590141] [G loss: 1.846311]\n",
      "./dataset_2018_05_16/12/\n",
      "576 [D loss real: 0.214128] [D loss fake: 0.413089] [D loss: 0.627217] [G loss: 1.788128]\n",
      "577 [D loss real: 0.278219] [D loss fake: 0.443014] [D loss: 0.721233] [G loss: 1.747631]\n",
      "578 [D loss real: 0.261825] [D loss fake: 0.411310] [D loss: 0.673135] [G loss: 1.734976]\n",
      "579 [D loss real: 0.233451] [D loss fake: 0.413554] [D loss: 0.647005] [G loss: 1.876599]\n",
      "580 [D loss real: 0.137920] [D loss fake: 0.424553] [D loss: 0.562474] [G loss: 1.858902]\n",
      "581 [D loss real: 0.179029] [D loss fake: 0.452323] [D loss: 0.631352] [G loss: 1.712210]\n",
      "582 [D loss real: 0.175724] [D loss fake: 0.411313] [D loss: 0.587038] [G loss: 1.775481]\n",
      "583 [D loss real: 0.247135] [D loss fake: 0.428909] [D loss: 0.676044] [G loss: 1.800911]\n",
      "584 [D loss real: 0.200859] [D loss fake: 0.438708] [D loss: 0.639567] [G loss: 1.783113]\n",
      "585 [D loss real: 0.101725] [D loss fake: 0.444655] [D loss: 0.546380] [G loss: 1.755806]\n",
      "586 [D loss real: 0.225252] [D loss fake: 0.436076] [D loss: 0.661328] [G loss: 1.784367]\n",
      "587 [D loss real: 0.296579] [D loss fake: 0.417300] [D loss: 0.713879] [G loss: 1.826417]\n",
      "588 [D loss real: 0.275667] [D loss fake: 0.417662] [D loss: 0.693329] [G loss: 1.841809]\n",
      "589 [D loss real: 0.201234] [D loss fake: 0.381644] [D loss: 0.582878] [G loss: 1.897231]\n",
      "./dataset_2018_05_16/13/\n",
      "590 [D loss real: 0.147615] [D loss fake: 0.433965] [D loss: 0.581580] [G loss: 1.933508]\n",
      "591 [D loss real: 0.169037] [D loss fake: 0.391571] [D loss: 0.560608] [G loss: 1.946414]\n",
      "592 [D loss real: 0.191983] [D loss fake: 0.444772] [D loss: 0.636755] [G loss: 1.802339]\n",
      "593 [D loss real: 0.176782] [D loss fake: 0.424553] [D loss: 0.601334] [G loss: 1.728757]\n",
      "594 [D loss real: 0.260335] [D loss fake: 0.424306] [D loss: 0.684640] [G loss: 1.789412]\n",
      "595 [D loss real: 0.147417] [D loss fake: 0.416621] [D loss: 0.564039] [G loss: 1.856053]\n",
      "596 [D loss real: 0.152459] [D loss fake: 0.394822] [D loss: 0.547280] [G loss: 1.815537]\n",
      "597 [D loss real: 0.215841] [D loss fake: 0.433533] [D loss: 0.649374] [G loss: 1.834059]\n",
      "598 [D loss real: 0.181621] [D loss fake: 0.424104] [D loss: 0.605725] [G loss: 1.817232]\n",
      "599 [D loss real: 0.267770] [D loss fake: 0.422456] [D loss: 0.690225] [G loss: 1.782851]\n",
      "600 [D loss real: 0.245875] [D loss fake: 0.399860] [D loss: 0.645735] [G loss: 1.859372]\n",
      "601 [D loss real: 0.184515] [D loss fake: 0.449184] [D loss: 0.633699] [G loss: 1.802480]\n",
      "602 [D loss real: 0.241449] [D loss fake: 0.426821] [D loss: 0.668270] [G loss: 1.738219]\n",
      "603 [D loss real: 0.196299] [D loss fake: 0.406792] [D loss: 0.603090] [G loss: 1.844922]\n",
      "./dataset_2018_05_16/14/\n",
      "604 [D loss real: 0.252262] [D loss fake: 0.414985] [D loss: 0.667247] [G loss: 1.892793]\n",
      "605 [D loss real: 0.339732] [D loss fake: 0.422459] [D loss: 0.762191] [G loss: 1.871240]\n",
      "606 [D loss real: 0.271811] [D loss fake: 0.386014] [D loss: 0.657826] [G loss: 1.879388]\n",
      "607 [D loss real: 0.270887] [D loss fake: 0.406237] [D loss: 0.677124] [G loss: 1.887301]\n",
      "608 [D loss real: 0.292479] [D loss fake: 0.430398] [D loss: 0.722877] [G loss: 1.826896]\n",
      "609 [D loss real: 0.207849] [D loss fake: 0.407796] [D loss: 0.615645] [G loss: 1.815866]\n",
      "610 [D loss real: 0.216346] [D loss fake: 0.409580] [D loss: 0.625926] [G loss: 1.868649]\n",
      "611 [D loss real: 0.177609] [D loss fake: 0.418405] [D loss: 0.596015] [G loss: 1.864638]\n",
      "612 [D loss real: 0.250519] [D loss fake: 0.446006] [D loss: 0.696525] [G loss: 1.799546]\n",
      "613 [D loss real: 0.286573] [D loss fake: 0.437063] [D loss: 0.723637] [G loss: 1.691274]\n",
      "614 [D loss real: 0.265983] [D loss fake: 0.395304] [D loss: 0.661287] [G loss: 1.809340]\n",
      "615 [D loss real: 0.256220] [D loss fake: 0.417509] [D loss: 0.673729] [G loss: 1.851810]\n",
      "616 [D loss real: 0.109684] [D loss fake: 0.414245] [D loss: 0.523929] [G loss: 1.882361]\n",
      "617 [D loss real: 0.202566] [D loss fake: 0.419458] [D loss: 0.622024] [G loss: 1.879735]\n",
      "./dataset_2018_05_16/15/\n",
      "618 [D loss real: 0.190784] [D loss fake: 0.416292] [D loss: 0.607076] [G loss: 1.775123]\n",
      "619 [D loss real: 0.168897] [D loss fake: 0.435305] [D loss: 0.604203] [G loss: 1.846816]\n",
      "620 [D loss real: 0.207471] [D loss fake: 0.449594] [D loss: 0.657065] [G loss: 1.684766]\n",
      "621 [D loss real: 0.138951] [D loss fake: 0.412429] [D loss: 0.551380] [G loss: 1.790548]\n",
      "622 [D loss real: 0.235221] [D loss fake: 0.434108] [D loss: 0.669329] [G loss: 1.803573]\n",
      "623 [D loss real: 0.167946] [D loss fake: 0.419766] [D loss: 0.587712] [G loss: 1.796496]\n",
      "624 [D loss real: 0.260594] [D loss fake: 0.409407] [D loss: 0.670000] [G loss: 1.858565]\n",
      "625 [D loss real: 0.185748] [D loss fake: 0.443112] [D loss: 0.628860] [G loss: 1.820541]\n",
      "626 [D loss real: 0.186443] [D loss fake: 0.421377] [D loss: 0.607820] [G loss: 1.816311]\n",
      "627 [D loss real: 0.210414] [D loss fake: 0.437072] [D loss: 0.647486] [G loss: 1.735638]\n",
      "628 [D loss real: 0.156696] [D loss fake: 0.397964] [D loss: 0.554659] [G loss: 1.858711]\n",
      "629 [D loss real: 0.221622] [D loss fake: 0.409119] [D loss: 0.630741] [G loss: 1.800703]\n",
      "630 [D loss real: 0.199403] [D loss fake: 0.417246] [D loss: 0.616649] [G loss: 1.862943]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "631 [D loss real: 0.119127] [D loss fake: 0.436234] [D loss: 0.555361] [G loss: 1.824684]\n",
      "./dataset_2018_05_16/1/\n",
      "632 [D loss real: 0.261895] [D loss fake: 0.448573] [D loss: 0.710468] [G loss: 1.723651]\n",
      "633 [D loss real: 0.262963] [D loss fake: 0.453149] [D loss: 0.716112] [G loss: 1.698956]\n",
      "634 [D loss real: 0.143908] [D loss fake: 0.414044] [D loss: 0.557952] [G loss: 1.778049]\n",
      "635 [D loss real: 0.238370] [D loss fake: 0.422746] [D loss: 0.661117] [G loss: 1.812306]\n",
      "636 [D loss real: 0.127433] [D loss fake: 0.385032] [D loss: 0.512465] [G loss: 1.912101]\n",
      "637 [D loss real: 0.224898] [D loss fake: 0.432325] [D loss: 0.657224] [G loss: 1.852487]\n",
      "638 [D loss real: 0.189236] [D loss fake: 0.449241] [D loss: 0.638477] [G loss: 1.717626]\n",
      "639 [D loss real: 0.276544] [D loss fake: 0.422107] [D loss: 0.698651] [G loss: 1.717401]\n",
      "640 [D loss real: 0.264633] [D loss fake: 0.422478] [D loss: 0.687110] [G loss: 1.819554]\n",
      "641 [D loss real: 0.211830] [D loss fake: 0.430016] [D loss: 0.641847] [G loss: 1.821159]\n",
      "642 [D loss real: 0.258355] [D loss fake: 0.436591] [D loss: 0.694947] [G loss: 1.773823]\n",
      "643 [D loss real: 0.166646] [D loss fake: 0.442422] [D loss: 0.609068] [G loss: 1.759275]\n",
      "644 [D loss real: 0.109756] [D loss fake: 0.415092] [D loss: 0.524848] [G loss: 1.796036]\n",
      "645 [D loss real: 0.109582] [D loss fake: 0.392817] [D loss: 0.502399] [G loss: 1.894030]\n",
      "./dataset_2018_05_16/2/\n",
      "646 [D loss real: 0.126242] [D loss fake: 0.400366] [D loss: 0.526608] [G loss: 1.908812]\n",
      "647 [D loss real: 0.122177] [D loss fake: 0.456975] [D loss: 0.579152] [G loss: 1.825400]\n",
      "648 [D loss real: 0.158030] [D loss fake: 0.430363] [D loss: 0.588393] [G loss: 1.718266]\n",
      "649 [D loss real: 0.126417] [D loss fake: 0.451286] [D loss: 0.577702] [G loss: 1.748947]\n",
      "650 [D loss real: 0.157594] [D loss fake: 0.424700] [D loss: 0.582294] [G loss: 1.766708]\n",
      "651 [D loss real: 0.168664] [D loss fake: 0.413322] [D loss: 0.581986] [G loss: 1.794671]\n",
      "652 [D loss real: 0.219690] [D loss fake: 0.422672] [D loss: 0.642362] [G loss: 1.816365]\n",
      "653 [D loss real: 0.248551] [D loss fake: 0.418156] [D loss: 0.666707] [G loss: 1.842901]\n",
      "654 [D loss real: 0.194223] [D loss fake: 0.445101] [D loss: 0.639324] [G loss: 1.772599]\n",
      "655 [D loss real: 0.196764] [D loss fake: 0.406138] [D loss: 0.602902] [G loss: 1.811979]\n",
      "656 [D loss real: 0.129267] [D loss fake: 0.398170] [D loss: 0.527436] [G loss: 1.902229]\n",
      "657 [D loss real: 0.270958] [D loss fake: 0.385803] [D loss: 0.656761] [G loss: 1.956774]\n",
      "658 [D loss real: 0.204159] [D loss fake: 0.418852] [D loss: 0.623012] [G loss: 1.891179]\n",
      "659 [D loss real: 0.131359] [D loss fake: 0.435572] [D loss: 0.566932] [G loss: 1.809478]\n",
      "./dataset_2018_05_16/3/\n",
      "660 [D loss real: 0.178052] [D loss fake: 0.414081] [D loss: 0.592132] [G loss: 1.832197]\n",
      "661 [D loss real: 0.210539] [D loss fake: 0.446027] [D loss: 0.656566] [G loss: 1.794512]\n",
      "662 [D loss real: 0.177541] [D loss fake: 0.432437] [D loss: 0.609978] [G loss: 1.798231]\n",
      "663 [D loss real: 0.246631] [D loss fake: 0.397565] [D loss: 0.644196] [G loss: 1.837191]\n",
      "664 [D loss real: 0.132587] [D loss fake: 0.428045] [D loss: 0.560631] [G loss: 1.810156]\n",
      "665 [D loss real: 0.100133] [D loss fake: 0.460708] [D loss: 0.560841] [G loss: 1.787636]\n",
      "666 [D loss real: 0.178168] [D loss fake: 0.404321] [D loss: 0.582489] [G loss: 1.768243]\n",
      "667 [D loss real: 0.182620] [D loss fake: 0.401019] [D loss: 0.583639] [G loss: 1.902154]\n",
      "668 [D loss real: 0.243053] [D loss fake: 0.423182] [D loss: 0.666235] [G loss: 1.845673]\n",
      "669 [D loss real: 0.232375] [D loss fake: 0.413896] [D loss: 0.646271] [G loss: 1.849669]\n",
      "670 [D loss real: 0.170683] [D loss fake: 0.442027] [D loss: 0.612710] [G loss: 1.782581]\n",
      "671 [D loss real: 0.129467] [D loss fake: 0.441594] [D loss: 0.571060] [G loss: 1.742622]\n",
      "672 [D loss real: 0.157333] [D loss fake: 0.455571] [D loss: 0.612903] [G loss: 1.697311]\n",
      "673 [D loss real: 0.119637] [D loss fake: 0.418243] [D loss: 0.537880] [G loss: 1.779235]\n",
      "./dataset_2018_05_16/4/\n",
      "674 [D loss real: 0.276429] [D loss fake: 0.415668] [D loss: 0.692096] [G loss: 1.816686]\n",
      "675 [D loss real: 0.259180] [D loss fake: 0.416185] [D loss: 0.675365] [G loss: 1.830447]\n",
      "676 [D loss real: 0.163351] [D loss fake: 0.428035] [D loss: 0.591386] [G loss: 1.803965]\n",
      "677 [D loss real: 0.103543] [D loss fake: 0.467463] [D loss: 0.571005] [G loss: 1.721645]\n",
      "678 [D loss real: 0.161810] [D loss fake: 0.411229] [D loss: 0.573040] [G loss: 1.764748]\n",
      "679 [D loss real: 0.338592] [D loss fake: 0.400581] [D loss: 0.739174] [G loss: 1.876694]\n",
      "680 [D loss real: 0.251727] [D loss fake: 0.419184] [D loss: 0.670911] [G loss: 1.918818]\n",
      "681 [D loss real: 0.111167] [D loss fake: 0.408142] [D loss: 0.519310] [G loss: 1.889756]\n",
      "682 [D loss real: 0.287510] [D loss fake: 0.386173] [D loss: 0.673683] [G loss: 1.847296]\n",
      "683 [D loss real: 0.202680] [D loss fake: 0.435274] [D loss: 0.637954] [G loss: 1.907533]\n",
      "684 [D loss real: 0.171225] [D loss fake: 0.449350] [D loss: 0.620575] [G loss: 1.774234]\n",
      "685 [D loss real: 0.235950] [D loss fake: 0.417193] [D loss: 0.653143] [G loss: 1.766394]\n",
      "686 [D loss real: 0.175076] [D loss fake: 0.439268] [D loss: 0.614344] [G loss: 1.792792]\n",
      "687 [D loss real: 0.233579] [D loss fake: 0.406080] [D loss: 0.639660] [G loss: 1.774106]\n",
      "./dataset_2018_05_16/5/\n",
      "688 [D loss real: 0.182516] [D loss fake: 0.427590] [D loss: 0.610106] [G loss: 1.808756]\n",
      "689 [D loss real: 0.229627] [D loss fake: 0.419653] [D loss: 0.649280] [G loss: 1.794892]\n",
      "690 [D loss real: 0.141139] [D loss fake: 0.424200] [D loss: 0.565339] [G loss: 1.819552]\n",
      "691 [D loss real: 0.147235] [D loss fake: 0.439292] [D loss: 0.586527] [G loss: 1.747613]\n",
      "692 [D loss real: 0.185205] [D loss fake: 0.409171] [D loss: 0.594376] [G loss: 1.742408]\n",
      "693 [D loss real: 0.188264] [D loss fake: 0.400766] [D loss: 0.589030] [G loss: 1.866278]\n",
      "694 [D loss real: 0.200471] [D loss fake: 0.431882] [D loss: 0.632353] [G loss: 1.867162]\n",
      "695 [D loss real: 0.072908] [D loss fake: 0.447847] [D loss: 0.520755] [G loss: 1.722188]\n",
      "696 [D loss real: 0.138058] [D loss fake: 0.440170] [D loss: 0.578228] [G loss: 1.684299]\n",
      "697 [D loss real: 0.199875] [D loss fake: 0.439066] [D loss: 0.638941] [G loss: 1.735817]\n",
      "698 [D loss real: 0.188544] [D loss fake: 0.429539] [D loss: 0.618083] [G loss: 1.727760]\n",
      "699 [D loss real: 0.160406] [D loss fake: 0.416649] [D loss: 0.577056] [G loss: 1.834118]\n",
      "700 [D loss real: 0.074508] [D loss fake: 0.442115] [D loss: 0.516623] [G loss: 1.803908]\n",
      "701 [D loss real: 0.207230] [D loss fake: 0.409060] [D loss: 0.616290] [G loss: 1.783473]\n",
      "./dataset_2018_05_16/6/\n",
      "702 [D loss real: 0.156874] [D loss fake: 0.406092] [D loss: 0.562966] [G loss: 1.834095]\n",
      "703 [D loss real: 0.218092] [D loss fake: 0.402403] [D loss: 0.620495] [G loss: 1.921596]\n",
      "704 [D loss real: 0.125362] [D loss fake: 0.436797] [D loss: 0.562160] [G loss: 1.843504]\n",
      "705 [D loss real: 0.213638] [D loss fake: 0.408955] [D loss: 0.622593] [G loss: 1.748989]\n",
      "706 [D loss real: 0.213099] [D loss fake: 0.412168] [D loss: 0.625267] [G loss: 1.836518]\n",
      "707 [D loss real: 0.118923] [D loss fake: 0.411932] [D loss: 0.530856] [G loss: 1.846862]\n",
      "708 [D loss real: 0.193109] [D loss fake: 0.441789] [D loss: 0.634898] [G loss: 1.849216]\n",
      "709 [D loss real: 0.117487] [D loss fake: 0.425053] [D loss: 0.542540] [G loss: 1.756158]\n",
      "710 [D loss real: 0.171077] [D loss fake: 0.403061] [D loss: 0.574138] [G loss: 1.857019]\n",
      "711 [D loss real: 0.127277] [D loss fake: 0.381065] [D loss: 0.508342] [G loss: 1.980750]\n",
      "712 [D loss real: 0.246504] [D loss fake: 0.442292] [D loss: 0.688796] [G loss: 1.914126]\n",
      "713 [D loss real: 0.282198] [D loss fake: 0.450337] [D loss: 0.732535] [G loss: 1.718273]\n",
      "714 [D loss real: 0.141765] [D loss fake: 0.450130] [D loss: 0.591895] [G loss: 1.716590]\n",
      "715 [D loss real: 0.262899] [D loss fake: 0.431814] [D loss: 0.694712] [G loss: 1.703389]\n",
      "./dataset_2018_05_16/7/\n",
      "716 [D loss real: 0.193241] [D loss fake: 0.413022] [D loss: 0.606263] [G loss: 1.870123]\n",
      "717 [D loss real: 0.207384] [D loss fake: 0.427035] [D loss: 0.634420] [G loss: 1.787558]\n",
      "718 [D loss real: 0.166818] [D loss fake: 0.439865] [D loss: 0.606683] [G loss: 1.765009]\n",
      "719 [D loss real: 0.208532] [D loss fake: 0.456702] [D loss: 0.665233] [G loss: 1.684752]\n",
      "720 [D loss real: 0.163754] [D loss fake: 0.416790] [D loss: 0.580545] [G loss: 1.818041]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "721 [D loss real: 0.186113] [D loss fake: 0.427153] [D loss: 0.613266] [G loss: 1.781986]\n",
      "722 [D loss real: 0.267869] [D loss fake: 0.451808] [D loss: 0.719677] [G loss: 1.725359]\n",
      "723 [D loss real: 0.134692] [D loss fake: 0.429506] [D loss: 0.564198] [G loss: 1.738758]\n",
      "724 [D loss real: 0.278457] [D loss fake: 0.459967] [D loss: 0.738424] [G loss: 1.744981]\n",
      "725 [D loss real: 0.185685] [D loss fake: 0.428662] [D loss: 0.614348] [G loss: 1.809497]\n",
      "726 [D loss real: 0.190739] [D loss fake: 0.409518] [D loss: 0.600257] [G loss: 1.808376]\n",
      "727 [D loss real: 0.167393] [D loss fake: 0.418264] [D loss: 0.585658] [G loss: 1.849611]\n",
      "728 [D loss real: 0.296977] [D loss fake: 0.420111] [D loss: 0.717088] [G loss: 1.768902]\n",
      "729 [D loss real: 0.256342] [D loss fake: 0.411898] [D loss: 0.668240] [G loss: 1.828978]\n",
      "./dataset_2018_05_16/8/\n",
      "730 [D loss real: 0.243177] [D loss fake: 0.419863] [D loss: 0.663040] [G loss: 1.812092]\n",
      "731 [D loss real: 0.225684] [D loss fake: 0.453079] [D loss: 0.678762] [G loss: 1.753852]\n",
      "732 [D loss real: 0.224681] [D loss fake: 0.445125] [D loss: 0.669806] [G loss: 1.744878]\n",
      "733 [D loss real: 0.230811] [D loss fake: 0.459822] [D loss: 0.690633] [G loss: 1.674020]\n",
      "734 [D loss real: 0.196276] [D loss fake: 0.405532] [D loss: 0.601808] [G loss: 1.832113]\n",
      "735 [D loss real: 0.196738] [D loss fake: 0.416591] [D loss: 0.613329] [G loss: 1.843694]\n",
      "736 [D loss real: 0.275415] [D loss fake: 0.425285] [D loss: 0.700700] [G loss: 1.846751]\n",
      "737 [D loss real: 0.190107] [D loss fake: 0.408585] [D loss: 0.598693] [G loss: 1.795704]\n",
      "738 [D loss real: 0.281509] [D loss fake: 0.433432] [D loss: 0.714941] [G loss: 1.772391]\n",
      "739 [D loss real: 0.248271] [D loss fake: 0.430696] [D loss: 0.678967] [G loss: 1.767755]\n",
      "740 [D loss real: 0.189877] [D loss fake: 0.442889] [D loss: 0.632766] [G loss: 1.761429]\n",
      "741 [D loss real: 0.197757] [D loss fake: 0.421006] [D loss: 0.618764] [G loss: 1.840570]\n",
      "742 [D loss real: 0.153099] [D loss fake: 0.374970] [D loss: 0.528068] [G loss: 1.872397]\n",
      "743 [D loss real: 0.199921] [D loss fake: 0.420134] [D loss: 0.620056] [G loss: 1.902958]\n",
      "./dataset_2018_05_16/9/\n",
      "744 [D loss real: 0.141899] [D loss fake: 0.397220] [D loss: 0.539119] [G loss: 1.877366]\n",
      "745 [D loss real: 0.136964] [D loss fake: 0.427340] [D loss: 0.564304] [G loss: 1.816870]\n",
      "746 [D loss real: 0.269761] [D loss fake: 0.418685] [D loss: 0.688446] [G loss: 1.780832]\n",
      "747 [D loss real: 0.280924] [D loss fake: 0.421624] [D loss: 0.702548] [G loss: 1.795674]\n",
      "748 [D loss real: 0.264716] [D loss fake: 0.443817] [D loss: 0.708533] [G loss: 1.742719]\n",
      "749 [D loss real: 0.197270] [D loss fake: 0.434723] [D loss: 0.631994] [G loss: 1.761677]\n",
      "750 [D loss real: 0.254303] [D loss fake: 0.429565] [D loss: 0.683868] [G loss: 1.834309]\n",
      "751 [D loss real: 0.072895] [D loss fake: 0.438157] [D loss: 0.511051] [G loss: 1.792003]\n",
      "752 [D loss real: 0.267660] [D loss fake: 0.445331] [D loss: 0.712990] [G loss: 1.788675]\n",
      "753 [D loss real: 0.175764] [D loss fake: 0.440461] [D loss: 0.616225] [G loss: 1.765287]\n",
      "754 [D loss real: 0.178869] [D loss fake: 0.434923] [D loss: 0.613791] [G loss: 1.802503]\n",
      "755 [D loss real: 0.208153] [D loss fake: 0.451145] [D loss: 0.659298] [G loss: 1.703709]\n",
      "756 [D loss real: 0.238289] [D loss fake: 0.413145] [D loss: 0.651434] [G loss: 1.818368]\n",
      "757 [D loss real: 0.141239] [D loss fake: 0.411449] [D loss: 0.552688] [G loss: 1.914320]\n",
      "./dataset_2018_05_16/10/\n",
      "758 [D loss real: 0.193774] [D loss fake: 0.441210] [D loss: 0.634984] [G loss: 1.819228]\n",
      "759 [D loss real: 0.108570] [D loss fake: 0.419316] [D loss: 0.527886] [G loss: 1.773290]\n",
      "760 [D loss real: 0.169931] [D loss fake: 0.431719] [D loss: 0.601650] [G loss: 1.829922]\n",
      "761 [D loss real: 0.257029] [D loss fake: 0.426515] [D loss: 0.683544] [G loss: 1.832008]\n",
      "762 [D loss real: 0.272559] [D loss fake: 0.397273] [D loss: 0.669833] [G loss: 1.872133]\n",
      "763 [D loss real: 0.203640] [D loss fake: 0.417413] [D loss: 0.621054] [G loss: 1.868812]\n",
      "764 [D loss real: 0.209086] [D loss fake: 0.392772] [D loss: 0.601858] [G loss: 1.807831]\n",
      "765 [D loss real: 0.168182] [D loss fake: 0.416270] [D loss: 0.584453] [G loss: 1.855158]\n",
      "766 [D loss real: 0.237309] [D loss fake: 0.421175] [D loss: 0.658485] [G loss: 1.818421]\n",
      "767 [D loss real: 0.156562] [D loss fake: 0.411721] [D loss: 0.568283] [G loss: 1.774536]\n",
      "768 [D loss real: 0.202719] [D loss fake: 0.392039] [D loss: 0.594757] [G loss: 1.835836]\n",
      "769 [D loss real: 0.266037] [D loss fake: 0.409825] [D loss: 0.675862] [G loss: 1.876308]\n",
      "770 [D loss real: 0.138354] [D loss fake: 0.412485] [D loss: 0.550839] [G loss: 1.851256]\n",
      "771 [D loss real: 0.223157] [D loss fake: 0.420856] [D loss: 0.644013] [G loss: 1.865742]\n",
      "./dataset_2018_05_16/11/\n",
      "772 [D loss real: 0.143201] [D loss fake: 0.430927] [D loss: 0.574128] [G loss: 1.773007]\n",
      "773 [D loss real: 0.223855] [D loss fake: 0.454455] [D loss: 0.678310] [G loss: 1.741846]\n",
      "774 [D loss real: 0.249762] [D loss fake: 0.449910] [D loss: 0.699671] [G loss: 1.759189]\n",
      "775 [D loss real: 0.219647] [D loss fake: 0.437103] [D loss: 0.656750] [G loss: 1.728061]\n",
      "776 [D loss real: 0.079743] [D loss fake: 0.416940] [D loss: 0.496683] [G loss: 1.804567]\n",
      "777 [D loss real: 0.223674] [D loss fake: 0.454815] [D loss: 0.678489] [G loss: 1.774517]\n",
      "778 [D loss real: 0.202049] [D loss fake: 0.439531] [D loss: 0.641580] [G loss: 1.685228]\n",
      "779 [D loss real: 0.213724] [D loss fake: 0.411310] [D loss: 0.625034] [G loss: 1.816536]\n",
      "780 [D loss real: 0.174797] [D loss fake: 0.382617] [D loss: 0.557414] [G loss: 1.930666]\n",
      "781 [D loss real: 0.113554] [D loss fake: 0.431799] [D loss: 0.545353] [G loss: 1.837373]\n",
      "782 [D loss real: 0.235974] [D loss fake: 0.400202] [D loss: 0.636176] [G loss: 1.863384]\n",
      "783 [D loss real: 0.210249] [D loss fake: 0.405773] [D loss: 0.616022] [G loss: 1.835249]\n",
      "784 [D loss real: 0.187010] [D loss fake: 0.422759] [D loss: 0.609769] [G loss: 1.857089]\n",
      "785 [D loss real: 0.201208] [D loss fake: 0.431276] [D loss: 0.632484] [G loss: 1.812502]\n",
      "./dataset_2018_05_16/12/\n",
      "786 [D loss real: 0.170623] [D loss fake: 0.434651] [D loss: 0.605274] [G loss: 1.771794]\n",
      "787 [D loss real: 0.220822] [D loss fake: 0.432762] [D loss: 0.653584] [G loss: 1.748685]\n",
      "788 [D loss real: 0.234997] [D loss fake: 0.411224] [D loss: 0.646222] [G loss: 1.845218]\n",
      "789 [D loss real: 0.251808] [D loss fake: 0.400329] [D loss: 0.652137] [G loss: 1.863809]\n",
      "790 [D loss real: 0.234279] [D loss fake: 0.395559] [D loss: 0.629838] [G loss: 1.902723]\n",
      "791 [D loss real: 0.138835] [D loss fake: 0.421543] [D loss: 0.560379] [G loss: 1.894672]\n",
      "792 [D loss real: 0.210308] [D loss fake: 0.430546] [D loss: 0.640854] [G loss: 1.822135]\n",
      "793 [D loss real: 0.149637] [D loss fake: 0.399268] [D loss: 0.548905] [G loss: 1.847674]\n",
      "794 [D loss real: 0.214816] [D loss fake: 0.382014] [D loss: 0.596830] [G loss: 1.977525]\n",
      "795 [D loss real: 0.204411] [D loss fake: 0.421312] [D loss: 0.625722] [G loss: 1.858432]\n",
      "796 [D loss real: 0.291696] [D loss fake: 0.417862] [D loss: 0.709559] [G loss: 1.823385]\n",
      "797 [D loss real: 0.216787] [D loss fake: 0.418451] [D loss: 0.635238] [G loss: 1.818926]\n",
      "798 [D loss real: 0.151613] [D loss fake: 0.441598] [D loss: 0.593211] [G loss: 1.792993]\n",
      "799 [D loss real: 0.336077] [D loss fake: 0.438950] [D loss: 0.775028] [G loss: 1.724422]\n",
      "./dataset_2018_05_16/13/\n",
      "800 [D loss real: 0.173210] [D loss fake: 0.430398] [D loss: 0.603608] [G loss: 1.760180]\n",
      "801 [D loss real: 0.221375] [D loss fake: 0.411272] [D loss: 0.632647] [G loss: 1.801786]\n",
      "802 [D loss real: 0.169344] [D loss fake: 0.458232] [D loss: 0.627575] [G loss: 1.768999]\n",
      "803 [D loss real: 0.233328] [D loss fake: 0.415680] [D loss: 0.649008] [G loss: 1.777386]\n",
      "804 [D loss real: 0.232410] [D loss fake: 0.444361] [D loss: 0.676771] [G loss: 1.724104]\n",
      "805 [D loss real: 0.214811] [D loss fake: 0.428459] [D loss: 0.643270] [G loss: 1.767501]\n",
      "806 [D loss real: 0.180014] [D loss fake: 0.395578] [D loss: 0.575592] [G loss: 1.862168]\n",
      "807 [D loss real: 0.169571] [D loss fake: 0.438396] [D loss: 0.607968] [G loss: 1.849867]\n",
      "808 [D loss real: 0.197687] [D loss fake: 0.427882] [D loss: 0.625569] [G loss: 1.797843]\n",
      "809 [D loss real: 0.248371] [D loss fake: 0.466165] [D loss: 0.714536] [G loss: 1.765070]\n",
      "810 [D loss real: 0.199303] [D loss fake: 0.424886] [D loss: 0.624189] [G loss: 1.674879]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "811 [D loss real: 0.133904] [D loss fake: 0.424552] [D loss: 0.558456] [G loss: 1.849724]\n",
      "812 [D loss real: 0.232950] [D loss fake: 0.408374] [D loss: 0.641324] [G loss: 1.832223]\n",
      "813 [D loss real: 0.101380] [D loss fake: 0.421013] [D loss: 0.522392] [G loss: 1.846824]\n",
      "./dataset_2018_05_16/14/\n",
      "814 [D loss real: 0.212705] [D loss fake: 0.409537] [D loss: 0.622242] [G loss: 1.863663]\n",
      "815 [D loss real: 0.239801] [D loss fake: 0.427187] [D loss: 0.666988] [G loss: 1.845382]\n",
      "816 [D loss real: 0.159123] [D loss fake: 0.371991] [D loss: 0.531114] [G loss: 1.890434]\n",
      "817 [D loss real: 0.176533] [D loss fake: 0.417630] [D loss: 0.594163] [G loss: 1.947944]\n",
      "818 [D loss real: 0.309687] [D loss fake: 0.445476] [D loss: 0.755162] [G loss: 1.751185]\n",
      "819 [D loss real: 0.265872] [D loss fake: 0.465196] [D loss: 0.731069] [G loss: 1.702731]\n",
      "820 [D loss real: 0.200356] [D loss fake: 0.419428] [D loss: 0.619784] [G loss: 1.765106]\n",
      "821 [D loss real: 0.215598] [D loss fake: 0.433654] [D loss: 0.649252] [G loss: 1.801753]\n",
      "822 [D loss real: 0.241512] [D loss fake: 0.429847] [D loss: 0.671359] [G loss: 1.771434]\n",
      "823 [D loss real: 0.168695] [D loss fake: 0.393606] [D loss: 0.562301] [G loss: 1.807203]\n",
      "824 [D loss real: 0.301655] [D loss fake: 0.429063] [D loss: 0.730718] [G loss: 1.853113]\n",
      "825 [D loss real: 0.197931] [D loss fake: 0.393771] [D loss: 0.591702] [G loss: 1.887665]\n",
      "826 [D loss real: 0.145653] [D loss fake: 0.408924] [D loss: 0.554577] [G loss: 1.921853]\n",
      "827 [D loss real: 0.165056] [D loss fake: 0.433077] [D loss: 0.598132] [G loss: 1.875551]\n",
      "828 [D loss real: 0.201466] [D loss fake: 0.431444] [D loss: 0.632910] [G loss: 1.797734]\n",
      "./dataset_2018_05_16/15/\n",
      "829 [D loss real: 0.195034] [D loss fake: 0.403485] [D loss: 0.598519] [G loss: 1.771602]\n",
      "830 [D loss real: 0.226485] [D loss fake: 0.453000] [D loss: 0.679486] [G loss: 1.737289]\n",
      "831 [D loss real: 0.270099] [D loss fake: 0.406695] [D loss: 0.676793] [G loss: 1.827572]\n",
      "832 [D loss real: 0.224138] [D loss fake: 0.407931] [D loss: 0.632069] [G loss: 1.868809]\n",
      "833 [D loss real: 0.220461] [D loss fake: 0.483346] [D loss: 0.703807] [G loss: 1.787437]\n",
      "834 [D loss real: 0.305864] [D loss fake: 0.439834] [D loss: 0.745697] [G loss: 1.650679]\n",
      "835 [D loss real: 0.193766] [D loss fake: 0.426118] [D loss: 0.619884] [G loss: 1.748286]\n",
      "836 [D loss real: 0.204425] [D loss fake: 0.411300] [D loss: 0.615725] [G loss: 1.923061]\n",
      "837 [D loss real: 0.273101] [D loss fake: 0.434564] [D loss: 0.707665] [G loss: 1.814845]\n",
      "838 [D loss real: 0.265425] [D loss fake: 0.397234] [D loss: 0.662659] [G loss: 1.819033]\n",
      "839 [D loss real: 0.179609] [D loss fake: 0.404680] [D loss: 0.584289] [G loss: 1.875406]\n",
      "840 [D loss real: 0.229599] [D loss fake: 0.437274] [D loss: 0.666873] [G loss: 1.901654]\n",
      "841 [D loss real: 0.223001] [D loss fake: 0.439148] [D loss: 0.662149] [G loss: 1.716913]\n",
      "842 [D loss real: 0.129250] [D loss fake: 0.427468] [D loss: 0.556718] [G loss: 1.758807]\n",
      "./dataset_2018_05_16/1/\n",
      "843 [D loss real: 0.158862] [D loss fake: 0.417728] [D loss: 0.576590] [G loss: 1.874378]\n",
      "844 [D loss real: 0.236204] [D loss fake: 0.399437] [D loss: 0.635642] [G loss: 1.905204]\n",
      "845 [D loss real: 0.163810] [D loss fake: 0.426791] [D loss: 0.590600] [G loss: 1.844828]\n",
      "846 [D loss real: 0.048592] [D loss fake: 0.416703] [D loss: 0.465295] [G loss: 1.840762]\n",
      "847 [D loss real: 0.215159] [D loss fake: 0.407978] [D loss: 0.623136] [G loss: 1.792600]\n",
      "848 [D loss real: 0.101560] [D loss fake: 0.415479] [D loss: 0.517040] [G loss: 1.786378]\n",
      "849 [D loss real: 0.243362] [D loss fake: 0.410623] [D loss: 0.653985] [G loss: 1.872338]\n",
      "850 [D loss real: 0.184581] [D loss fake: 0.453855] [D loss: 0.638436] [G loss: 1.736382]\n",
      "851 [D loss real: 0.150383] [D loss fake: 0.433350] [D loss: 0.583734] [G loss: 1.769150]\n",
      "852 [D loss real: 0.262539] [D loss fake: 0.428457] [D loss: 0.690997] [G loss: 1.745945]\n",
      "853 [D loss real: 0.178155] [D loss fake: 0.442225] [D loss: 0.620380] [G loss: 1.805268]\n",
      "854 [D loss real: 0.119285] [D loss fake: 0.439503] [D loss: 0.558788] [G loss: 1.746295]\n",
      "855 [D loss real: 0.289517] [D loss fake: 0.403204] [D loss: 0.692721] [G loss: 1.780254]\n",
      "856 [D loss real: 0.262777] [D loss fake: 0.410787] [D loss: 0.673564] [G loss: 1.894321]\n",
      "./dataset_2018_05_16/2/\n",
      "857 [D loss real: 0.173299] [D loss fake: 0.407039] [D loss: 0.580338] [G loss: 1.842871]\n",
      "858 [D loss real: 0.184490] [D loss fake: 0.465907] [D loss: 0.650396] [G loss: 1.785072]\n",
      "859 [D loss real: 0.238930] [D loss fake: 0.426513] [D loss: 0.665443] [G loss: 1.748209]\n",
      "860 [D loss real: 0.235254] [D loss fake: 0.441387] [D loss: 0.676641] [G loss: 1.744080]\n",
      "861 [D loss real: 0.244851] [D loss fake: 0.441840] [D loss: 0.686691] [G loss: 1.744154]\n",
      "862 [D loss real: 0.232253] [D loss fake: 0.412905] [D loss: 0.645158] [G loss: 1.775929]\n",
      "863 [D loss real: 0.153320] [D loss fake: 0.419476] [D loss: 0.572797] [G loss: 1.887111]\n",
      "864 [D loss real: 0.166371] [D loss fake: 0.422138] [D loss: 0.588508] [G loss: 1.793091]\n",
      "865 [D loss real: 0.222119] [D loss fake: 0.429753] [D loss: 0.651871] [G loss: 1.768635]\n",
      "866 [D loss real: 0.245492] [D loss fake: 0.412779] [D loss: 0.658271] [G loss: 1.794040]\n",
      "867 [D loss real: 0.179377] [D loss fake: 0.420185] [D loss: 0.599562] [G loss: 1.859338]\n",
      "868 [D loss real: 0.112189] [D loss fake: 0.430979] [D loss: 0.543169] [G loss: 1.780081]\n",
      "869 [D loss real: 0.293462] [D loss fake: 0.387753] [D loss: 0.681215] [G loss: 1.896465]\n",
      "870 [D loss real: 0.185451] [D loss fake: 0.458000] [D loss: 0.643450] [G loss: 1.785753]\n",
      "./dataset_2018_05_16/3/\n",
      "871 [D loss real: 0.205778] [D loss fake: 0.418440] [D loss: 0.624218] [G loss: 1.754455]\n",
      "872 [D loss real: 0.199282] [D loss fake: 0.439741] [D loss: 0.639024] [G loss: 1.850745]\n",
      "873 [D loss real: 0.166108] [D loss fake: 0.413375] [D loss: 0.579483] [G loss: 1.875419]\n",
      "874 [D loss real: 0.218107] [D loss fake: 0.423553] [D loss: 0.641660] [G loss: 1.925587]\n",
      "875 [D loss real: 0.274960] [D loss fake: 0.428902] [D loss: 0.703862] [G loss: 1.784455]\n",
      "876 [D loss real: 0.156329] [D loss fake: 0.443898] [D loss: 0.600227] [G loss: 1.706378]\n",
      "877 [D loss real: 0.196684] [D loss fake: 0.439707] [D loss: 0.636391] [G loss: 1.725878]\n",
      "878 [D loss real: 0.225015] [D loss fake: 0.399574] [D loss: 0.624590] [G loss: 1.869271]\n",
      "879 [D loss real: 0.185272] [D loss fake: 0.402849] [D loss: 0.588121] [G loss: 1.875475]\n",
      "880 [D loss real: 0.221391] [D loss fake: 0.421447] [D loss: 0.642839] [G loss: 1.850064]\n",
      "881 [D loss real: 0.124437] [D loss fake: 0.422132] [D loss: 0.546570] [G loss: 1.830225]\n",
      "882 [D loss real: 0.239952] [D loss fake: 0.445053] [D loss: 0.685005] [G loss: 1.725081]\n",
      "883 [D loss real: 0.183831] [D loss fake: 0.433882] [D loss: 0.617713] [G loss: 1.747256]\n",
      "884 [D loss real: 0.176765] [D loss fake: 0.433895] [D loss: 0.610660] [G loss: 1.718701]\n",
      "./dataset_2018_05_16/4/\n",
      "885 [D loss real: 0.290748] [D loss fake: 0.414479] [D loss: 0.705228] [G loss: 1.866319]\n",
      "886 [D loss real: 0.144243] [D loss fake: 0.404726] [D loss: 0.548969] [G loss: 1.964187]\n",
      "887 [D loss real: 0.216625] [D loss fake: 0.437458] [D loss: 0.654083] [G loss: 1.818470]\n",
      "888 [D loss real: 0.293986] [D loss fake: 0.418184] [D loss: 0.712170] [G loss: 1.838737]\n",
      "889 [D loss real: 0.247950] [D loss fake: 0.431690] [D loss: 0.679640] [G loss: 1.780770]\n",
      "890 [D loss real: 0.196350] [D loss fake: 0.384716] [D loss: 0.581066] [G loss: 1.835200]\n",
      "891 [D loss real: 0.158524] [D loss fake: 0.402181] [D loss: 0.560705] [G loss: 1.910722]\n",
      "892 [D loss real: 0.208036] [D loss fake: 0.381379] [D loss: 0.589415] [G loss: 1.912488]\n",
      "893 [D loss real: 0.165443] [D loss fake: 0.432798] [D loss: 0.598242] [G loss: 1.868651]\n",
      "894 [D loss real: 0.231184] [D loss fake: 0.469774] [D loss: 0.700958] [G loss: 1.657462]\n",
      "895 [D loss real: 0.261613] [D loss fake: 0.435619] [D loss: 0.697231] [G loss: 1.688478]\n",
      "896 [D loss real: 0.196353] [D loss fake: 0.437312] [D loss: 0.633665] [G loss: 1.788545]\n",
      "897 [D loss real: 0.230578] [D loss fake: 0.413123] [D loss: 0.643700] [G loss: 1.847862]\n",
      "898 [D loss real: 0.183331] [D loss fake: 0.409719] [D loss: 0.593050] [G loss: 1.849291]\n",
      "./dataset_2018_05_16/5/\n",
      "899 [D loss real: 0.125327] [D loss fake: 0.372476] [D loss: 0.497803] [G loss: 2.029770]\n",
      "900 [D loss real: 0.203493] [D loss fake: 0.418697] [D loss: 0.622190] [G loss: 1.934416]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "901 [D loss real: 0.212310] [D loss fake: 0.401655] [D loss: 0.613966] [G loss: 1.846912]\n",
      "902 [D loss real: 0.130998] [D loss fake: 0.392690] [D loss: 0.523688] [G loss: 1.828327]\n",
      "903 [D loss real: 0.203739] [D loss fake: 0.421184] [D loss: 0.624923] [G loss: 1.925707]\n",
      "904 [D loss real: 0.139788] [D loss fake: 0.426678] [D loss: 0.566466] [G loss: 1.800565]\n",
      "905 [D loss real: 0.190672] [D loss fake: 0.447273] [D loss: 0.637945] [G loss: 1.780000]\n",
      "906 [D loss real: 0.176826] [D loss fake: 0.408873] [D loss: 0.585698] [G loss: 1.780201]\n",
      "907 [D loss real: 0.293293] [D loss fake: 0.416144] [D loss: 0.709438] [G loss: 1.827168]\n",
      "908 [D loss real: 0.215671] [D loss fake: 0.453521] [D loss: 0.669192] [G loss: 1.729436]\n",
      "909 [D loss real: 0.189250] [D loss fake: 0.390863] [D loss: 0.580113] [G loss: 1.828083]\n",
      "910 [D loss real: 0.091648] [D loss fake: 0.428681] [D loss: 0.520329] [G loss: 1.887994]\n",
      "911 [D loss real: 0.228080] [D loss fake: 0.443020] [D loss: 0.671101] [G loss: 1.814334]\n",
      "912 [D loss real: 0.220551] [D loss fake: 0.434261] [D loss: 0.654812] [G loss: 1.699587]\n",
      "./dataset_2018_05_16/6/\n",
      "913 [D loss real: 0.193532] [D loss fake: 0.450565] [D loss: 0.644097] [G loss: 1.677034]\n",
      "914 [D loss real: 0.261816] [D loss fake: 0.411687] [D loss: 0.673503] [G loss: 1.823698]\n",
      "915 [D loss real: 0.256044] [D loss fake: 0.412995] [D loss: 0.669039] [G loss: 1.874925]\n",
      "916 [D loss real: 0.309242] [D loss fake: 0.416576] [D loss: 0.725818] [G loss: 1.870162]\n",
      "917 [D loss real: 0.206378] [D loss fake: 0.423242] [D loss: 0.629619] [G loss: 1.750218]\n",
      "918 [D loss real: 0.172087] [D loss fake: 0.411792] [D loss: 0.583879] [G loss: 1.870824]\n",
      "919 [D loss real: 0.151674] [D loss fake: 0.437249] [D loss: 0.588923] [G loss: 1.804528]\n",
      "920 [D loss real: 0.205144] [D loss fake: 0.432578] [D loss: 0.637722] [G loss: 1.804751]\n",
      "921 [D loss real: 0.252982] [D loss fake: 0.424662] [D loss: 0.677644] [G loss: 1.834534]\n",
      "922 [D loss real: 0.222473] [D loss fake: 0.405977] [D loss: 0.628450] [G loss: 1.824256]\n",
      "923 [D loss real: 0.223061] [D loss fake: 0.400955] [D loss: 0.624017] [G loss: 1.886077]\n",
      "924 [D loss real: 0.214633] [D loss fake: 0.441935] [D loss: 0.656569] [G loss: 1.808307]\n",
      "925 [D loss real: 0.202573] [D loss fake: 0.432777] [D loss: 0.635350] [G loss: 1.808768]\n",
      "926 [D loss real: 0.163797] [D loss fake: 0.394467] [D loss: 0.558264] [G loss: 1.827793]\n",
      "./dataset_2018_05_16/7/\n",
      "927 [D loss real: 0.166832] [D loss fake: 0.453926] [D loss: 0.620758] [G loss: 1.878850]\n",
      "928 [D loss real: 0.235149] [D loss fake: 0.443372] [D loss: 0.678522] [G loss: 1.706860]\n",
      "929 [D loss real: 0.262657] [D loss fake: 0.425536] [D loss: 0.688192] [G loss: 1.837460]\n",
      "930 [D loss real: 0.221590] [D loss fake: 0.406321] [D loss: 0.627912] [G loss: 1.878423]\n",
      "931 [D loss real: 0.213733] [D loss fake: 0.458939] [D loss: 0.672672] [G loss: 1.782651]\n",
      "932 [D loss real: 0.241005] [D loss fake: 0.406791] [D loss: 0.647797] [G loss: 1.773288]\n",
      "933 [D loss real: 0.321675] [D loss fake: 0.404475] [D loss: 0.726150] [G loss: 1.814810]\n",
      "934 [D loss real: 0.246873] [D loss fake: 0.447419] [D loss: 0.694292] [G loss: 1.768715]\n",
      "935 [D loss real: 0.159974] [D loss fake: 0.403605] [D loss: 0.563579] [G loss: 1.894524]\n",
      "936 [D loss real: 0.133998] [D loss fake: 0.433753] [D loss: 0.567752] [G loss: 1.831288]\n",
      "937 [D loss real: 0.212813] [D loss fake: 0.393468] [D loss: 0.606281] [G loss: 1.841586]\n",
      "938 [D loss real: 0.255673] [D loss fake: 0.422246] [D loss: 0.677919] [G loss: 1.836323]\n",
      "939 [D loss real: 0.183742] [D loss fake: 0.430947] [D loss: 0.614688] [G loss: 1.768970]\n",
      "940 [D loss real: 0.236197] [D loss fake: 0.440895] [D loss: 0.677092] [G loss: 1.783478]\n",
      "./dataset_2018_05_16/8/\n",
      "941 [D loss real: 0.156657] [D loss fake: 0.393699] [D loss: 0.550356] [G loss: 1.868333]\n",
      "942 [D loss real: 0.110766] [D loss fake: 0.411346] [D loss: 0.522112] [G loss: 1.933173]\n",
      "943 [D loss real: 0.177884] [D loss fake: 0.401033] [D loss: 0.578917] [G loss: 1.909465]\n",
      "944 [D loss real: 0.189667] [D loss fake: 0.400268] [D loss: 0.589935] [G loss: 1.903747]\n",
      "945 [D loss real: 0.240366] [D loss fake: 0.434568] [D loss: 0.674933] [G loss: 1.845541]\n",
      "946 [D loss real: 0.221172] [D loss fake: 0.428728] [D loss: 0.649900] [G loss: 1.778515]\n",
      "947 [D loss real: 0.296663] [D loss fake: 0.440324] [D loss: 0.736987] [G loss: 1.751847]\n",
      "948 [D loss real: 0.190837] [D loss fake: 0.422461] [D loss: 0.613298] [G loss: 1.788967]\n",
      "949 [D loss real: 0.191291] [D loss fake: 0.401593] [D loss: 0.592884] [G loss: 1.867111]\n",
      "950 [D loss real: 0.271665] [D loss fake: 0.423097] [D loss: 0.694762] [G loss: 1.828645]\n",
      "951 [D loss real: 0.261324] [D loss fake: 0.436139] [D loss: 0.697463] [G loss: 1.791931]\n",
      "952 [D loss real: 0.127665] [D loss fake: 0.407919] [D loss: 0.535584] [G loss: 1.781773]\n",
      "953 [D loss real: 0.133638] [D loss fake: 0.418580] [D loss: 0.552219] [G loss: 1.834401]\n",
      "954 [D loss real: 0.070833] [D loss fake: 0.394143] [D loss: 0.464976] [G loss: 1.830611]\n",
      "./dataset_2018_05_16/9/\n",
      "955 [D loss real: 0.216602] [D loss fake: 0.427207] [D loss: 0.643809] [G loss: 1.851740]\n",
      "956 [D loss real: 0.240514] [D loss fake: 0.417135] [D loss: 0.657648] [G loss: 1.798133]\n",
      "957 [D loss real: 0.126297] [D loss fake: 0.413389] [D loss: 0.539686] [G loss: 1.806462]\n",
      "958 [D loss real: 0.251702] [D loss fake: 0.427803] [D loss: 0.679505] [G loss: 1.865697]\n",
      "959 [D loss real: 0.238259] [D loss fake: 0.421929] [D loss: 0.660187] [G loss: 1.802785]\n",
      "960 [D loss real: 0.211741] [D loss fake: 0.434153] [D loss: 0.645894] [G loss: 1.829355]\n",
      "961 [D loss real: 0.248911] [D loss fake: 0.414999] [D loss: 0.663910] [G loss: 1.838444]\n",
      "962 [D loss real: 0.152076] [D loss fake: 0.391691] [D loss: 0.543767] [G loss: 1.953691]\n",
      "963 [D loss real: 0.164488] [D loss fake: 0.444084] [D loss: 0.608572] [G loss: 1.843092]\n",
      "964 [D loss real: 0.198336] [D loss fake: 0.407741] [D loss: 0.606077] [G loss: 1.803280]\n",
      "965 [D loss real: 0.322045] [D loss fake: 0.408557] [D loss: 0.730603] [G loss: 1.863344]\n",
      "966 [D loss real: 0.249315] [D loss fake: 0.432427] [D loss: 0.681742] [G loss: 1.853767]\n",
      "967 [D loss real: 0.207881] [D loss fake: 0.421198] [D loss: 0.629079] [G loss: 1.837376]\n",
      "968 [D loss real: 0.205858] [D loss fake: 0.416467] [D loss: 0.622326] [G loss: 1.834041]\n",
      "./dataset_2018_05_16/10/\n",
      "969 [D loss real: 0.118431] [D loss fake: 0.424439] [D loss: 0.542870] [G loss: 1.877873]\n",
      "970 [D loss real: 0.069651] [D loss fake: 0.393340] [D loss: 0.462991] [G loss: 1.866815]\n",
      "971 [D loss real: 0.189612] [D loss fake: 0.420670] [D loss: 0.610282] [G loss: 1.903653]\n",
      "972 [D loss real: 0.068636] [D loss fake: 0.437472] [D loss: 0.506108] [G loss: 1.772172]\n",
      "973 [D loss real: 0.161010] [D loss fake: 0.434851] [D loss: 0.595862] [G loss: 1.753455]\n",
      "974 [D loss real: 0.129108] [D loss fake: 0.399796] [D loss: 0.528904] [G loss: 1.819652]\n",
      "975 [D loss real: 0.217233] [D loss fake: 0.458754] [D loss: 0.675987] [G loss: 1.767944]\n",
      "976 [D loss real: 0.271525] [D loss fake: 0.415615] [D loss: 0.687140] [G loss: 1.787121]\n",
      "977 [D loss real: 0.221031] [D loss fake: 0.432820] [D loss: 0.653851] [G loss: 1.828208]\n",
      "978 [D loss real: 0.139343] [D loss fake: 0.410657] [D loss: 0.550001] [G loss: 1.872779]\n",
      "979 [D loss real: 0.297017] [D loss fake: 0.422068] [D loss: 0.719085] [G loss: 1.819652]\n",
      "980 [D loss real: 0.083812] [D loss fake: 0.412058] [D loss: 0.495870] [G loss: 1.847089]\n",
      "981 [D loss real: 0.284089] [D loss fake: 0.446223] [D loss: 0.730312] [G loss: 1.744698]\n",
      "982 [D loss real: 0.136349] [D loss fake: 0.400853] [D loss: 0.537202] [G loss: 1.831496]\n",
      "./dataset_2018_05_16/11/\n",
      "983 [D loss real: 0.128480] [D loss fake: 0.417088] [D loss: 0.545568] [G loss: 1.862102]\n",
      "984 [D loss real: 0.140329] [D loss fake: 0.446775] [D loss: 0.587105] [G loss: 1.822695]\n",
      "985 [D loss real: 0.154998] [D loss fake: 0.419919] [D loss: 0.574916] [G loss: 1.757988]\n",
      "986 [D loss real: 0.170327] [D loss fake: 0.386729] [D loss: 0.557056] [G loss: 1.955569]\n",
      "987 [D loss real: 0.178623] [D loss fake: 0.411473] [D loss: 0.590096] [G loss: 1.880668]\n",
      "988 [D loss real: 0.149541] [D loss fake: 0.453089] [D loss: 0.602630] [G loss: 1.693945]\n",
      "989 [D loss real: 0.223444] [D loss fake: 0.453785] [D loss: 0.677229] [G loss: 1.629997]\n",
      "990 [D loss real: 0.150177] [D loss fake: 0.413340] [D loss: 0.563517] [G loss: 1.810836]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "991 [D loss real: 0.180550] [D loss fake: 0.404762] [D loss: 0.585312] [G loss: 1.943638]\n",
      "992 [D loss real: 0.187022] [D loss fake: 0.434274] [D loss: 0.621297] [G loss: 1.845617]\n",
      "993 [D loss real: 0.237145] [D loss fake: 0.447276] [D loss: 0.684421] [G loss: 1.724636]\n",
      "994 [D loss real: 0.218453] [D loss fake: 0.410552] [D loss: 0.629004] [G loss: 1.792433]\n",
      "995 [D loss real: 0.287362] [D loss fake: 0.378124] [D loss: 0.665486] [G loss: 1.939098]\n",
      "996 [D loss real: 0.258837] [D loss fake: 0.422676] [D loss: 0.681513] [G loss: 1.916975]\n",
      "./dataset_2018_05_16/12/\n",
      "997 [D loss real: 0.187577] [D loss fake: 0.431247] [D loss: 0.618824] [G loss: 1.881225]\n",
      "998 [D loss real: 0.207258] [D loss fake: 0.389159] [D loss: 0.596417] [G loss: 1.870266]\n",
      "999 [D loss real: 0.297546] [D loss fake: 0.381021] [D loss: 0.678566] [G loss: 1.941576]\n",
      "1000 [D loss real: 0.208375] [D loss fake: 0.420980] [D loss: 0.629355] [G loss: 1.891995]\n",
      "gan imaga2 :  (128, 128, 1)\n",
      "1001 [D loss real: 0.200199] [D loss fake: 0.436574] [D loss: 0.636773] [G loss: 1.844026]\n",
      "1002 [D loss real: 0.296504] [D loss fake: 0.417216] [D loss: 0.713720] [G loss: 1.740745]\n",
      "1003 [D loss real: 0.134237] [D loss fake: 0.409830] [D loss: 0.544067] [G loss: 1.920717]\n",
      "1004 [D loss real: 0.202630] [D loss fake: 0.423173] [D loss: 0.625804] [G loss: 1.775382]\n",
      "1005 [D loss real: 0.177755] [D loss fake: 0.395047] [D loss: 0.572802] [G loss: 1.810457]\n",
      "1006 [D loss real: 0.170547] [D loss fake: 0.431177] [D loss: 0.601724] [G loss: 1.878169]\n",
      "1007 [D loss real: 0.250678] [D loss fake: 0.407689] [D loss: 0.658367] [G loss: 1.854769]\n",
      "1008 [D loss real: 0.141360] [D loss fake: 0.445403] [D loss: 0.586763] [G loss: 1.754995]\n",
      "1009 [D loss real: 0.220038] [D loss fake: 0.395197] [D loss: 0.615235] [G loss: 1.789808]\n",
      "1010 [D loss real: 0.139923] [D loss fake: 0.421616] [D loss: 0.561540] [G loss: 1.900621]\n",
      "./dataset_2018_05_16/13/\n",
      "1011 [D loss real: 0.172454] [D loss fake: 0.380412] [D loss: 0.552865] [G loss: 1.974856]\n",
      "1012 [D loss real: 0.256216] [D loss fake: 0.384736] [D loss: 0.640952] [G loss: 1.932661]\n",
      "1013 [D loss real: 0.188803] [D loss fake: 0.435059] [D loss: 0.623862] [G loss: 1.889057]\n",
      "1014 [D loss real: 0.229851] [D loss fake: 0.453328] [D loss: 0.683179] [G loss: 1.699061]\n",
      "1015 [D loss real: 0.146455] [D loss fake: 0.419220] [D loss: 0.565675] [G loss: 1.804597]\n",
      "1016 [D loss real: 0.292056] [D loss fake: 0.431448] [D loss: 0.723505] [G loss: 1.762266]\n",
      "1017 [D loss real: 0.171343] [D loss fake: 0.439694] [D loss: 0.611037] [G loss: 1.807228]\n",
      "1018 [D loss real: 0.228801] [D loss fake: 0.407197] [D loss: 0.635998] [G loss: 1.793988]\n",
      "1019 [D loss real: 0.170194] [D loss fake: 0.443280] [D loss: 0.613474] [G loss: 1.765638]\n",
      "1020 [D loss real: 0.205480] [D loss fake: 0.426320] [D loss: 0.631800] [G loss: 1.757542]\n",
      "1021 [D loss real: 0.254884] [D loss fake: 0.405624] [D loss: 0.660508] [G loss: 1.854179]\n",
      "1022 [D loss real: 0.197045] [D loss fake: 0.425929] [D loss: 0.622974] [G loss: 1.869116]\n",
      "1023 [D loss real: 0.197992] [D loss fake: 0.415941] [D loss: 0.613933] [G loss: 1.836738]\n",
      "1024 [D loss real: 0.277510] [D loss fake: 0.442127] [D loss: 0.719637] [G loss: 1.808572]\n",
      "./dataset_2018_05_16/14/\n",
      "1025 [D loss real: 0.105210] [D loss fake: 0.429110] [D loss: 0.534320] [G loss: 1.766443]\n",
      "1026 [D loss real: 0.221045] [D loss fake: 0.418998] [D loss: 0.640043] [G loss: 1.780021]\n",
      "1027 [D loss real: 0.102922] [D loss fake: 0.459225] [D loss: 0.562147] [G loss: 1.763448]\n",
      "1028 [D loss real: 0.220749] [D loss fake: 0.441004] [D loss: 0.661753] [G loss: 1.688556]\n",
      "1029 [D loss real: 0.233604] [D loss fake: 0.427420] [D loss: 0.661025] [G loss: 1.801630]\n",
      "1030 [D loss real: 0.261756] [D loss fake: 0.457883] [D loss: 0.719640] [G loss: 1.703095]\n",
      "1031 [D loss real: 0.241366] [D loss fake: 0.438536] [D loss: 0.679903] [G loss: 1.641124]\n",
      "1032 [D loss real: 0.150233] [D loss fake: 0.438037] [D loss: 0.588270] [G loss: 1.794306]\n",
      "1033 [D loss real: 0.234189] [D loss fake: 0.407162] [D loss: 0.641351] [G loss: 1.768308]\n",
      "1034 [D loss real: 0.222126] [D loss fake: 0.424783] [D loss: 0.646910] [G loss: 1.768924]\n",
      "1035 [D loss real: 0.157497] [D loss fake: 0.411999] [D loss: 0.569497] [G loss: 1.829899]\n",
      "1036 [D loss real: 0.135398] [D loss fake: 0.423931] [D loss: 0.559329] [G loss: 1.798856]\n",
      "1037 [D loss real: 0.183283] [D loss fake: 0.417737] [D loss: 0.601020] [G loss: 1.780423]\n",
      "1038 [D loss real: 0.228818] [D loss fake: 0.438556] [D loss: 0.667375] [G loss: 1.780097]\n",
      "./dataset_2018_05_16/15/\n",
      "1039 [D loss real: 0.278184] [D loss fake: 0.426530] [D loss: 0.704714] [G loss: 1.766412]\n",
      "1040 [D loss real: 0.243646] [D loss fake: 0.394175] [D loss: 0.637821] [G loss: 1.873483]\n",
      "1041 [D loss real: 0.110415] [D loss fake: 0.415623] [D loss: 0.526038] [G loss: 1.954331]\n",
      "1042 [D loss real: 0.187055] [D loss fake: 0.443626] [D loss: 0.630680] [G loss: 1.752574]\n",
      "1043 [D loss real: 0.208782] [D loss fake: 0.397073] [D loss: 0.605855] [G loss: 1.837633]\n",
      "1044 [D loss real: 0.175158] [D loss fake: 0.449831] [D loss: 0.624989] [G loss: 1.798584]\n",
      "1045 [D loss real: 0.199519] [D loss fake: 0.417772] [D loss: 0.617291] [G loss: 1.781025]\n",
      "1046 [D loss real: 0.166065] [D loss fake: 0.441717] [D loss: 0.607782] [G loss: 1.751210]\n",
      "1047 [D loss real: 0.182902] [D loss fake: 0.420473] [D loss: 0.603375] [G loss: 1.797999]\n",
      "1048 [D loss real: 0.228190] [D loss fake: 0.436832] [D loss: 0.665022] [G loss: 1.796811]\n",
      "1049 [D loss real: 0.334909] [D loss fake: 0.423775] [D loss: 0.758684] [G loss: 1.751069]\n",
      "1050 [D loss real: 0.192542] [D loss fake: 0.451928] [D loss: 0.644469] [G loss: 1.776371]\n",
      "1051 [D loss real: 0.200109] [D loss fake: 0.413955] [D loss: 0.614064] [G loss: 1.846925]\n",
      "1052 [D loss real: 0.227488] [D loss fake: 0.427543] [D loss: 0.655031] [G loss: 1.872587]\n",
      "./dataset_2018_05_16/1/\n",
      "1053 [D loss real: 0.243394] [D loss fake: 0.425945] [D loss: 0.669339] [G loss: 1.782828]\n",
      "1054 [D loss real: 0.220663] [D loss fake: 0.414747] [D loss: 0.635410] [G loss: 1.854230]\n",
      "1055 [D loss real: 0.230460] [D loss fake: 0.447235] [D loss: 0.677695] [G loss: 1.754999]\n",
      "1056 [D loss real: 0.158880] [D loss fake: 0.451697] [D loss: 0.610578] [G loss: 1.656919]\n",
      "1057 [D loss real: 0.113531] [D loss fake: 0.390660] [D loss: 0.504190] [G loss: 1.832480]\n",
      "1058 [D loss real: 0.213821] [D loss fake: 0.442547] [D loss: 0.656368] [G loss: 1.874123]\n",
      "1059 [D loss real: 0.194879] [D loss fake: 0.417451] [D loss: 0.612330] [G loss: 1.813435]\n",
      "1060 [D loss real: 0.204808] [D loss fake: 0.434430] [D loss: 0.639238] [G loss: 1.801430]\n",
      "1061 [D loss real: 0.145691] [D loss fake: 0.417486] [D loss: 0.563177] [G loss: 1.823549]\n",
      "1062 [D loss real: 0.239821] [D loss fake: 0.381931] [D loss: 0.621752] [G loss: 1.908097]\n",
      "1063 [D loss real: 0.199543] [D loss fake: 0.434058] [D loss: 0.633600] [G loss: 1.846335]\n",
      "1064 [D loss real: 0.220469] [D loss fake: 0.415215] [D loss: 0.635684] [G loss: 1.794555]\n",
      "1065 [D loss real: 0.313574] [D loss fake: 0.438673] [D loss: 0.752247] [G loss: 1.768733]\n",
      "1066 [D loss real: 0.225687] [D loss fake: 0.394737] [D loss: 0.620424] [G loss: 1.843546]\n",
      "./dataset_2018_05_16/2/\n",
      "1067 [D loss real: 0.254532] [D loss fake: 0.424415] [D loss: 0.678947] [G loss: 1.866576]\n",
      "1068 [D loss real: 0.159475] [D loss fake: 0.445864] [D loss: 0.605340] [G loss: 1.745163]\n",
      "1069 [D loss real: 0.132495] [D loss fake: 0.405511] [D loss: 0.538006] [G loss: 1.807982]\n",
      "1070 [D loss real: 0.200670] [D loss fake: 0.384397] [D loss: 0.585067] [G loss: 1.887052]\n",
      "1071 [D loss real: 0.271926] [D loss fake: 0.451821] [D loss: 0.723747] [G loss: 1.835148]\n",
      "1072 [D loss real: 0.137560] [D loss fake: 0.392998] [D loss: 0.530558] [G loss: 1.854506]\n",
      "1073 [D loss real: 0.268651] [D loss fake: 0.423913] [D loss: 0.692563] [G loss: 1.867834]\n",
      "1074 [D loss real: 0.188036] [D loss fake: 0.433712] [D loss: 0.621748] [G loss: 1.817748]\n",
      "1075 [D loss real: 0.139525] [D loss fake: 0.410266] [D loss: 0.549791] [G loss: 1.805842]\n",
      "1076 [D loss real: 0.318777] [D loss fake: 0.430338] [D loss: 0.749116] [G loss: 1.765957]\n",
      "1077 [D loss real: 0.255528] [D loss fake: 0.398784] [D loss: 0.654312] [G loss: 1.861686]\n",
      "1078 [D loss real: 0.285101] [D loss fake: 0.400809] [D loss: 0.685910] [G loss: 1.947494]\n",
      "1079 [D loss real: 0.281711] [D loss fake: 0.391010] [D loss: 0.672722] [G loss: 1.932963]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080 [D loss real: 0.122516] [D loss fake: 0.425833] [D loss: 0.548349] [G loss: 1.897169]\n",
      "./dataset_2018_05_16/3/\n",
      "1081 [D loss real: 0.276081] [D loss fake: 0.424032] [D loss: 0.700113] [G loss: 1.810246]\n",
      "1082 [D loss real: 0.226327] [D loss fake: 0.387790] [D loss: 0.614116] [G loss: 1.856520]\n",
      "1083 [D loss real: 0.278443] [D loss fake: 0.408030] [D loss: 0.686473] [G loss: 1.904776]\n",
      "1084 [D loss real: 0.283326] [D loss fake: 0.388320] [D loss: 0.671645] [G loss: 1.843569]\n",
      "1085 [D loss real: 0.189533] [D loss fake: 0.427991] [D loss: 0.617524] [G loss: 1.876135]\n",
      "1086 [D loss real: 0.188869] [D loss fake: 0.425997] [D loss: 0.614867] [G loss: 1.839846]\n",
      "1087 [D loss real: 0.142461] [D loss fake: 0.432812] [D loss: 0.575273] [G loss: 1.774851]\n",
      "1088 [D loss real: 0.127216] [D loss fake: 0.410658] [D loss: 0.537875] [G loss: 1.804924]\n",
      "1089 [D loss real: 0.116157] [D loss fake: 0.443248] [D loss: 0.559404] [G loss: 1.790253]\n",
      "1090 [D loss real: 0.210840] [D loss fake: 0.421406] [D loss: 0.632246] [G loss: 1.786306]\n",
      "1091 [D loss real: 0.227788] [D loss fake: 0.402849] [D loss: 0.630637] [G loss: 1.821918]\n",
      "1092 [D loss real: 0.256944] [D loss fake: 0.439528] [D loss: 0.696472] [G loss: 1.795904]\n",
      "1093 [D loss real: 0.209738] [D loss fake: 0.435696] [D loss: 0.645434] [G loss: 1.805301]\n",
      "1094 [D loss real: 0.148040] [D loss fake: 0.441867] [D loss: 0.589907] [G loss: 1.743246]\n",
      "./dataset_2018_05_16/4/\n",
      "1095 [D loss real: 0.248121] [D loss fake: 0.422982] [D loss: 0.671103] [G loss: 1.789633]\n",
      "1096 [D loss real: 0.112825] [D loss fake: 0.447010] [D loss: 0.559835] [G loss: 1.729853]\n",
      "1097 [D loss real: 0.160890] [D loss fake: 0.419214] [D loss: 0.580103] [G loss: 1.773684]\n",
      "1098 [D loss real: 0.237432] [D loss fake: 0.427407] [D loss: 0.664840] [G loss: 1.817444]\n",
      "1099 [D loss real: 0.243948] [D loss fake: 0.432417] [D loss: 0.676365] [G loss: 1.776678]\n",
      "1100 [D loss real: 0.135392] [D loss fake: 0.427439] [D loss: 0.562832] [G loss: 1.792202]\n",
      "1101 [D loss real: 0.242525] [D loss fake: 0.413794] [D loss: 0.656319] [G loss: 1.821436]\n",
      "1102 [D loss real: 0.143017] [D loss fake: 0.410351] [D loss: 0.553368] [G loss: 1.876032]\n",
      "1103 [D loss real: 0.179086] [D loss fake: 0.433132] [D loss: 0.612218] [G loss: 1.791883]\n",
      "1104 [D loss real: 0.274737] [D loss fake: 0.449219] [D loss: 0.723955] [G loss: 1.713995]\n",
      "1105 [D loss real: 0.151581] [D loss fake: 0.442790] [D loss: 0.594371] [G loss: 1.687566]\n",
      "1106 [D loss real: 0.230661] [D loss fake: 0.435888] [D loss: 0.666549] [G loss: 1.801923]\n",
      "1107 [D loss real: 0.305696] [D loss fake: 0.445776] [D loss: 0.751472] [G loss: 1.754058]\n",
      "1108 [D loss real: 0.243426] [D loss fake: 0.404965] [D loss: 0.648391] [G loss: 1.795642]\n",
      "./dataset_2018_05_16/5/\n",
      "1109 [D loss real: 0.182926] [D loss fake: 0.399329] [D loss: 0.582255] [G loss: 1.955966]\n",
      "1110 [D loss real: 0.284015] [D loss fake: 0.424486] [D loss: 0.708500] [G loss: 1.820842]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'  #  tensorflow\n",
    "# os.environ['THEANO_FLAGS']='floatX=float32,device=cuda,exception_verbosity=high'\n",
    "os.environ['THEANO_FLAGS'] = 'floatX=float32,device=cuda,optimizer=fast_compile'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"8\"\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "K.set_image_data_format('channels_last')\n",
    "\n",
    "import time\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, ZeroPadding2D, BatchNormalization, Input, LSTM, Concatenate, Dense, Dropout\n",
    "from keras.layers import Conv2DTranspose, Reshape, Activation, Cropping2D, Flatten, UpSampling2D, AveragePooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.activations import relu\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.datasets import mnist\n",
    "from urllib.request import urlretrieve\n",
    "from keras.optimizers import RMSprop, SGD, Adam, sgd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import model_from_json\n",
    "\n",
    "# from read_data import *\n",
    "a = % pwd\n",
    "print(a)\n",
    "\n",
    "% run/root/jupyter/inspace/sang-min/myo_proejct/load_data.py import DataLoader\n",
    "\n",
    "# %load load_data import DataLoader\n",
    "# from load_data import DataLoader\n",
    "\n",
    "\n",
    "'''\n",
    "Model structure\n",
    "\n",
    "Input : (100) Vector\n",
    "Output : (64, 64, 1) image\n",
    "\n",
    "Generator\n",
    "100 -> 256\n",
    "256 -> 16 x 16\n",
    "16 x 16 -> 32 x 32\n",
    "32 x 32 -> 64 x 64\n",
    "64 x 64 -> 128 x 128\n",
    "\n",
    "Discriminator\n",
    "128 x 128 -> 64 x 64\n",
    "64 x 64 -> 32 x 32\n",
    "32 x 32 -> 16 x 16\n",
    "16 x 16 -> 8 x 8\n",
    "8 x 8 -> 64\n",
    "64 -> 32 (16, 10)\n",
    "\n",
    "'''\n",
    "\n",
    "class MYO_GAN():\n",
    "    def __init__(self):\n",
    "        self.conv_init = RandomNormal(0, 0.02)\n",
    "        self.gamma_init = RandomNormal(1., 0.02)\n",
    "\n",
    "        self.epoch = 30000\n",
    "        self.time_0 = time.time()\n",
    "        self.batch_size = 64\n",
    "\n",
    "        self.d_step = 1\n",
    "        self.g_step = 2\n",
    "\n",
    "        self.g_loss_history = []\n",
    "        self.d_loss_real_history = []\n",
    "        self.d_loss_fake_history = []\n",
    "\n",
    "        self.lstm_size = (300, 16)\n",
    "        self.noise_size = 100\n",
    "        self.image_size = 128\n",
    "        self.input_size = 100\n",
    "        self.image_channel = 1\n",
    "        self.learning_rate = 2e-4\n",
    "        self.loader = DataLoader(data_path='./dataset_2018_05_16/', is_real_image=False)\n",
    "\n",
    "        self.discriminator_optim = sgd(lr=0.01, momentum=0.9, nesterov=True)\n",
    "        self.generator_optim = Adam(lr=1e-3)\n",
    "        adam = Adam(lr=0.0002, beta_1=0.5, beta_2=0.999)  # as described in appendix A of DeepMind's AC-GAN paper\n",
    "\n",
    "        # lstm_input = Input(shape=lstm_size)\n",
    "        self.noise_input = Input(shape=(self.noise_size,))\n",
    "        real_image = Input(shape=(self.image_size, self.image_size, self.image_channel))\n",
    "\n",
    "        self.net_g = self.generative_model()\n",
    "        fake_image = self.net_g(self.noise_input)\n",
    "        self.net_g.summary()\n",
    "\n",
    "        self.net_d = self.discriminative_model()\n",
    "        self.net_d.summary()\n",
    "\n",
    "        combined_output = self.net_d(fake_image)\n",
    "        self.combined_model = Model(inputs=[self.noise_input], outputs=[combined_output], name='combined')\n",
    "        '''\n",
    "        net_g, net_d, combined_model = load_model()\n",
    "\n",
    "        net_g.summary()\n",
    "        net_d.summary()\n",
    "\n",
    "        fake_image = net_g(self.noise_input)\n",
    "        '''\n",
    "        self.net_g.compile(loss='binary_crossentropy', optimizer=adam)\n",
    "        self.net_d.compile(loss='binary_crossentropy', optimizer=adam)\n",
    "        self.net_d.trainable = False\n",
    "        self.combined_model.compile(loss='binary_crossentropy', optimizer=adam)\n",
    "\n",
    "        self.combined_model.summary()\n",
    "\n",
    "    def generative_model(self):\n",
    "        #noise_input = Input(shape=(self.noise_size,))\n",
    "        \n",
    "        _ = Dense(256, input_shape=(100,), activation='relu')(self.noise_input)\n",
    "        _ = BatchNormalization(axis=1)(_, training=1)\n",
    "        _ = Reshape((16, 16, 1), input_shape=(256,))(_)\n",
    "\n",
    "        _ = Conv2D(filters=128, kernel_size=(3, 3), strides=1, padding='same', input_shape=(16, 16, 1))(\n",
    "            _)\n",
    "        _ = BatchNormalization(axis=1)(_, training=1)\n",
    "        _ = Activation(activation='relu')(_)\n",
    "\n",
    "        _ = UpSampling2D()(_)\n",
    "        _ = Conv2D(filters=256, kernel_size=3, padding='same', input_shape=(16, 16, 128))(_)\n",
    "        _ = BatchNormalization(axis=1)(_, training=1)\n",
    "        _ = Activation(activation='relu')(_)\n",
    "\n",
    "        _ = UpSampling2D()(_)\n",
    "        _ = Conv2D(filters=512, kernel_size=3, padding='same', input_shape=(32, 32, 256))(_)\n",
    "        _ = BatchNormalization(axis=1)(_, training=1)\n",
    "        _ = Activation(activation='relu')(_)\n",
    "\n",
    "        _ = UpSampling2D()(_)\n",
    "        _ = Conv2D(filters=256, kernel_size=3, padding='same', input_shape=(64, 64, 512))(_)\n",
    "        _ = BatchNormalization(axis=1)(_, training=1)\n",
    "        _ = Activation(activation='relu')(_)\n",
    "\n",
    "        # _ = UpSampling2D()(_)\n",
    "        _ = Conv2D(filters=1, kernel_size=3, padding='same', input_shape=(128, 128, 256))(_)\n",
    "        _ = Activation(activation='tanh')(_)\n",
    "\n",
    "\n",
    "        return Model(inputs=self.noise_input, outputs=_)\n",
    "\n",
    "\n",
    "    def discriminative_model(self):\n",
    "        _ = inputs = Input(shape=(self.image_size, self.image_size, self.image_channel))\n",
    "\n",
    "        _ = Conv2D(filters=256, kernel_size=(2, 2), strides=2, padding='same', input_shape=(128, 128, 1))(_)\n",
    "        _ = LeakyReLU(alpha=0.2)(_)\n",
    "\n",
    "        _ = BatchNormalization(axis=1)(_, training=1)\n",
    "        _ = Conv2D(filters=512, kernel_size=(1, 1), strides=2, padding='same', input_shape=(64, 64, 256))(_)\n",
    "        _ = LeakyReLU(alpha=0.2)(_)\n",
    "\n",
    "        _ = BatchNormalization(axis=1)(_, training=1)\n",
    "        _ = Conv2D(filters=256, kernel_size=(2, 2), strides=2, padding='same', input_shape=(32, 32, 512))(_)\n",
    "        _ = LeakyReLU(alpha=0.2)(_)\n",
    "\n",
    "        _ = BatchNormalization(axis=1)(_, training=1)\n",
    "        _ = Conv2D(filters=128, kernel_size=(2, 2), strides=2, padding='same', input_shape=(16, 16, 256))(_)\n",
    "        _ = LeakyReLU(alpha=0.2)(_)\n",
    "\n",
    "        _ = BatchNormalization(axis=1)(_, training=1)\n",
    "        _ = Conv2D(filters=128, kernel_size=(2, 2), strides=2, padding='same', input_shape=(8, 8, 128))(_)\n",
    "        _ = LeakyReLU(alpha=0.2)(_)\n",
    "\n",
    "        _ = BatchNormalization(axis=1)(_, training=1)\n",
    "        _ = Conv2D(filters=self.image_channel, kernel_size=(2, 2), strides=1, padding='same', input_shape=(4, 4, 128))(_)\n",
    "        # _ = LeakyReLU(alpha=0.2)(_)\n",
    "\n",
    "        outputs = Flatten()(_)\n",
    "        outputs = Dense(1, activation='sigmoid')(outputs)\n",
    "\n",
    "        return Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    def load_model(self):\n",
    "        json_file = open('./model3_output/load_model/g_model.json', 'r')\n",
    "        loaded_model_json = json_file.read()\n",
    "        json_file.close()\n",
    "        load_g_model = model_from_json(loaded_model_json)\n",
    "        # load weights into new model\n",
    "        load_g_model.load_weights(\"./model3_output/load_model/g_model.h5\")\n",
    "\n",
    "        json_file = open('./model3_output/load_model/d_model.json', 'r')\n",
    "        loaded_model_json = json_file.read()\n",
    "        json_file.close()\n",
    "        load_d_model = model_from_json(loaded_model_json)\n",
    "        # load weights into new model\n",
    "        load_d_model.load_weights(\"./model3_output/load_model/d_model.h5\")\n",
    "\n",
    "        json_file = open('./model3_output/load_model/combined_model.json', 'r')\n",
    "        loaded_model_json = json_file.read()\n",
    "        json_file.close()\n",
    "        load_combined_model = model_from_json(loaded_model_json)\n",
    "        # load weights into new model\n",
    "        load_combined_model.load_weights(\"./model3_output/load_model/combined_model.h5\")\n",
    "\n",
    "        print(\"Loaded model from disk\")\n",
    "\n",
    "        return [load_g_model, load_d_model, load_combined_model]\n",
    "\n",
    "    def sample_generation(self):\n",
    "        for _ in range(num):\n",
    "            noise = np.random.normal(size=[num, self.noise_size])\n",
    "            gan_image = net_g.predict(noise)\n",
    "            cv2.imwrite('./model3_output/image/' + 'sample image' + str(_) + '.png', gan_image[_] * 127.5)\n",
    "\n",
    "        print(\"generated image\")\n",
    "\n",
    "    def save_model(self):\n",
    "        self.net_g.save_weights(\"./model3_output/save_model/g_model.h5\")\n",
    "        self.net_d.save_weights(\"./model3_output/save_model/d_model.h5\")\n",
    "        self.combined_model.save_weights(\"./model3_output/save_model/combined_model.h5\")\n",
    "\n",
    "        g_model_json = self.net_g.to_json()\n",
    "        with open(\"./model3_output/save_model/g_model.json\", \"w\") as json_file:\n",
    "            json_file.write(g_model_json)\n",
    "\n",
    "        d_model_json = self.net_d.to_json()\n",
    "        with open(\"./model3_output/save_model/d_model.json\", \"w\") as json_file:\n",
    "            json_file.write(d_model_json)\n",
    "\n",
    "        combined_model_json = self.combined_model.to_json()\n",
    "        with open(\"./model3_output/save_model/combined_model.json\", \"w\") as json_file:\n",
    "            json_file.write(combined_model_json)\n",
    "\n",
    "        print(\"Saved model to disk\")\n",
    "\n",
    "    def train(self):\n",
    "        i = 0\n",
    "\n",
    "        while i <= self.epoch:\n",
    "            # x_train = loader.get_emg_datas(batch_size)\n",
    "            images = self.loader.get_images(self.batch_size)\n",
    "\n",
    "            for _ in range(self.d_step):\n",
    "                noise = np.random.normal(size=[self.batch_size, self.noise_size])\n",
    "\n",
    "                g_z = self.net_g.predict(noise)\n",
    "\n",
    "                d_loss_real = self.net_d.train_on_batch(images, np.random.uniform(low=0.7, high=1.2, size=self.batch_size))\n",
    "                d_loss_fake = self.net_d.train_on_batch(g_z, np.random.uniform(low=0.0, high=0.3, size=self.batch_size))\n",
    "\n",
    "                self.d_loss_real_history.append(d_loss_real)\n",
    "                self.d_loss_fake_history.append(d_loss_fake)\n",
    "                self.d_loss = np.sum([d_loss_fake, d_loss_real])\n",
    "\n",
    "            for _ in range(self.g_step):\n",
    "                noise = np.random.normal(size=[self.batch_size, self.noise_size])\n",
    "                combined_loss = self.combined_model.train_on_batch(noise,np.random.uniform(low=0.7, high=1.2, size=self.batch_size))\n",
    "\n",
    "                self.g_loss_history.append(combined_loss)\n",
    "\n",
    "            print(\"%d [D loss real: %f] [D loss fake: %f] [D loss: %f] [G loss: %f]\" % (\n",
    "                i, d_loss_real, d_loss_fake, self.d_loss, combined_loss))\n",
    "\n",
    "            if i % 500 == 0:\n",
    "                gan_image = self.net_g.predict(noise)\n",
    "                print(\"gan imaga2 : \", gan_image[0].shape)\n",
    "                cv2.imwrite('./model3_output/image/' + 'fake_image' + str(i) + '.png', gan_image[0] * 127.5)\n",
    "                # cv2.imwrite('./output_image3/' + 'real_image'+ str(i) + '.png', images[0] * 127.5)\n",
    "\n",
    "            i += 1;\n",
    "\n",
    "        self.sample_generation(32, self.net_g)\n",
    "\n",
    "    def show_history(self):\n",
    "        plt.figure(1, figsize=(16, 8))\n",
    "        plt.plot(self.d_loss_real_history)\n",
    "        plt.ylabel('d_loss_real')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train'], loc='upper left')\n",
    "\n",
    "        plt.savefig('./model3_output/image/d_loss_real_history.png')\n",
    "\n",
    "        plt.figure(2, figsize=(16, 8))\n",
    "        plt.plot(self.d_loss_fake_history)\n",
    "        plt.ylabel('d_loss_fake')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train'], loc='upper left')\n",
    "\n",
    "        plt.savefig('./model3_output/image/d_loss_fake_history.png')\n",
    "\n",
    "        # plt.show()\n",
    "\n",
    "        plt.figure(3, figsize=(16, 8))\n",
    "        plt.plot(self.g_loss_history)\n",
    "        plt.ylabel('g_loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train'], loc='upper left')\n",
    "\n",
    "        plt.savefig('./model3_output/image/g_loss_history.png')\n",
    "\n",
    "        # plt.show()\\\n",
    "\n",
    "        plt.show()\n",
    "if __name__ == '__main__':\n",
    "    myo_gan = MYO_GAN()\n",
    "    myo_gan.train()\n",
    "\n",
    "    print(\"Finish\")\n",
    "\n",
    "'''\n",
    "net_g = generative_model(noise_size, image_channel)\n",
    "fake_image = net_g(noise_input)\n",
    "net_g.summary()\n",
    "\n",
    "net_d = discriminative_model(image_size, image_channel)\n",
    "net_d.summary()\n",
    "\n",
    "combined_output = net_d(fake_image)\n",
    "combined_model = Model(inputs=[noise_input], outputs=[combined_output], name='combined')\n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "loader = DataLoader(data_path='./MYO_Dataset_label/')\n",
    "\n",
    "emg = loader.load_emg_data()\n",
    "image, label = loader.load_image()\n",
    "\n",
    "print(emg.shape)\n",
    "print(image.shape, label)\n",
    "\n",
    "emg = loader.get_emg_datas(10)\n",
    "images, labels = loader.get_images(10)\n",
    "print(emg.shape, images.shape, labels.shape)\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
